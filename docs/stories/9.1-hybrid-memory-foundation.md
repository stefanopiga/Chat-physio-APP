# Story 9.1: Hybrid Memory Foundation

## Status
Draft

## Story

**As a** studente fisioterapia,
**I want** la mia cronologia conversazionale salvata in modo permanente nel database,
**so that** le mie conversazioni non vengano perse al riavvio dell'applicazione e possa accedere allo storico completo delle mie sessioni.

## Acceptance Criteria

1. Sistema implementa architettura Hybrid Memory con due livelli:
   - L1 Cache (in-memory): mantiene ultimi 3 turni per LLM context window (<2000 token)
   - L2 Storage (database): persiste storico completo illimitato

2. Tutti i messaggi conversazionali vengono persistiti automaticamente nel database in modo asincrono senza impattare latenza chat, con backpressure per limitare queue depth (max 100 pending tasks) e circuit breaker per proteggere DB durante overload (3 consecutive failures o p95 latency >1s → open per 30s)

3. Feature flag `ENABLE_PERSISTENT_MEMORY` controlla abilitazione persistence layer con graceful degradation se disabled

4. Database PostgreSQL contiene tutti i nuovi indici ottimizzati per query cronologiche, full-text search e analytics:
   - `idx_chat_messages_session_created` per query sessione ordinata
   - `idx_chat_messages_created_at` per analytics temporali
   - `idx_chat_messages_content_fts` per ricerca full-text italiano
   - `idx_chat_messages_metadata_archived` per filtro sessioni archiviate

5. Implementazione mantiene backward compatibility completa con Story 7.1 (short-term memory in-memory)

6. Sistema degrada gracefully a modalità in-memory only se database non disponibile (zero downtime)

7. Metriche implementate per monitoraggio:
   - `db_writes_succeeded` / `db_writes_failed` / `db_writes_timeout`
   - `db_write_latency_ms` histogram
   - `cache_hits` / `cache_misses`
   - `active_sessions_count` gauge
   - `backpressure_activated` counter (queue depth exceeded)
   - `circuit_breaker_open` gauge (0=closed, 1=open)
   - `outbox_queue_depth` gauge (messaggi in pending retry)
   - `retry_attempts_total` counter (tentativi retry)
   - `dlq_messages_total` counter (dead-letter queue)

8. Coverage test minimo 80% per tutti i nuovi moduli (`ConversationPersistenceService`, `HybridConversationManager`)

9. Sistema implementa durable outbox pattern per garantire eventual consistency: messaggi persistiti su disk queue (`.data/persistence_outbox.jsonl`) se DB unavailable, retry automatico con exponential backoff (1s→60s max), idempotency keys deterministici `sha256(session_id + timestamp + content_hash)` per prevenire duplicati, dead-letter queue per failures >10 retry attempts

## Tasks / Subtasks

- [ ] Task 1: Implementare ConversationPersistenceService (AC: 1, 2, 6, 9) — 4-5h
  - [ ] 1.1: Creare file `apps/api/api/services/persistence_service.py` con classe base e asyncpg pool initialization
  - [ ] 1.2: Implementare metodo `save_messages()` con bulk insert SQL, idempotency keys `sha256(session_id + timestamp_ms + content_hash)` e ON CONFLICT (idempotency_key) DO NOTHING con logging structured conflicts
  - [ ] 1.3: Implementare metodo `load_session_history()` con pagination e filtro archived
  - [ ] 1.4: Aggiungere error handling con logging strutturato per fallimenti DB
  - [ ] 1.5: Unit test per persistence service con mock asyncpg pool (coverage 80%+)

- [ ] Task 2: Creare database migration per nuovi indici (AC: 4, 9) — 1.5h
  - [ ] 2.1: Creare migration SQL in `supabase/migrations/YYYYMMDDHHMMSS_epic9_conversational_memory_indices.sql`
  - [ ] 2.2: Definire 5 indici: session_created, created_at, content_fts (GIN), metadata_archived (partial), UNIQUE idx_chat_messages_idempotency_key ON (idempotency_key) per enforce anti-duplicazione
  - [ ] 2.3: Eseguire migration su database development
  - [ ] 2.4: Verificare creazione indici con query `\di` PostgreSQL e test duplicazione con ON CONFLICT behavior

- [ ] Task 3: Refactoring ConversationManager → HybridConversationManager (AC: 1, 2, 5) — 6-7h
  - [ ] 3.1: Creare classe `HybridConversationManager` che estende `ConversationManager` in `apps/api/api/services/conversation_service.py`
  - [ ] 3.2: Aggiungere dependency injection per `ConversationPersistenceService` nel costruttore
  - [ ] 3.3: Override metodo `add_turn()` per dual-write: sync L1 cache + async L2 DB
  - [ ] 3.4: Implementare `_async_persist()` con error handling, timeout 5s e metrics collection
  - [ ] 3.5: Implementare `load_full_history()` per query DB completa (bypass L1 cache)
  - [ ] 3.6: Mantenere metodo `get_context_window()` invariato per backward compatibility
  - [ ] 3.7: Integration test per dual-write flow: verify cache + DB persistence
  - [ ] 3.8: Implementare bounded queue per `_write_tasks` con drop oldest policy (MAX_PENDING_WRITES=100)
  - [ ] 3.9: Implementare `CircuitBreaker` class con state machine (CLOSED→OPEN→HALF_OPEN, threshold=3, timeout=30s)
  - [ ] 3.10: Integrare circuit breaker in `_async_persist()` con metrics `circuit_breaker_open` gauge
  - [ ] 3.11: Test backpressure: enqueue >100 tasks → verify oldest dropped + `backpressure_activated` incremented
  - [ ] 3.12: Test circuit breaker: 3 consecutive failures → verify OPEN state + subsequent calls fail fast

- [ ] Task 4: Implementare Feature Flag configuration (AC: 3) — 1h
  - [ ] 4.1: Aggiungere campo `enable_persistent_memory: bool` a Settings in `apps/api/api/core/config.py`
  - [ ] 4.2: Aggiungere env var `ENABLE_PERSISTENT_MEMORY` in `.env` e `.env.example` (default: false)
  - [ ] 4.3: Modificare factory `get_conversation_manager()` per conditional initialization persistence service
  - [ ] 4.4: Test con flag ON e OFF: verify comportamento L1-only vs Hybrid

- [ ] Task 5: Graceful Degradation & Error Handling (AC: 6) — 2h
  - [ ] 5.1: Implementare try-catch in `_async_persist()` per DB connection errors
  - [ ] 5.2: Logging warning su fallimento persistence con continuation normal flow
  - [ ] 5.3: Metrics increment per failures: `db_writes_failed`, `db_writes_timeout`
  - [ ] 5.4: Test scenario: mock DB unavailable → verify chat continues with L1 cache only

- [ ] Task 6: Monitoring & Metrics Integration (AC: 7) — 1-2h
  - [ ] 6.1: Implementare counters: `db_writes_succeeded`, `db_writes_failed`, `db_writes_timeout`
  - [ ] 6.2: Implementare histogram: `db_write_latency_ms` per tracking performance
  - [ ] 6.3: Implementare counters: `cache_hits`, `cache_misses` in `get_context_window()`
  - [ ] 6.4: Implementare gauge: `active_sessions_count` aggiornato su add_turn/clear_session
  - [ ] 6.5: Test metrics collection: verify increment dopo operations

- [ ] Task 7: Integration Testing End-to-End (AC: 8) — 2h
  - [ ] 7.1: Test flow completo: `add_turn()` → wait async → `load_full_history()` → verify DB content
  - [ ] 7.2: Test pagination: inserire 150 messaggi → verify `load_session_history(limit=100, offset=50)`
  - [ ] 7.3: Test graceful degradation: kill DB → verify chat continua + L1 cache funziona
  - [ ] 7.4: Test backward compatibility: verify Story 7.1 behavior con flag OFF
  - [ ] 7.5: Performance test: verify `db_write_latency_ms` p95 < 100ms per 100 samples

- [ ] Task 8: Implementare Durable Outbox & Retry (AC: 9) — 3-4h
  - [ ] 8.1: Creare `OutboxPersistenceQueue` classe in `apps/api/api/services/outbox_queue.py` con disk-based queue (`.data/persistence_outbox.jsonl`)
  - [ ] 8.2: Implementare `append()` metodo per append-only log con timestamp e retry_count
  - [ ] 8.3: Implementare `_generate_idempotency_key()` con `sha256(session_id + timestamp + content_hash)`
  - [ ] 8.4: Implementare `retry_pending()` background loop con exponential backoff (1s→2s→4s→8s→max 60s)
  - [ ] 8.5: Implementare `_move_to_dlq()` per messaggi con retry_count >= 10 → `.data/persistence_dlq.jsonl`
  - [ ] 8.6: Integrare outbox in `HybridConversationManager._async_persist()`: fallback su outbox se DB write fails
  - [ ] 8.7: Unit test idempotency: duplicate message ID → verify same key generated
  - [ ] 8.8: Integration test durability: kill DB → verify outbox append → restart → verify retry success + eventual consistency
  - [ ] 8.9: Test dead-letter queue: mock 10 consecutive failures → verify DLQ entry + `dlq_messages_total` incremented

## Dev Notes

**RIFERIMENTO TECNICO CRITICO**: Consultare `docs/architecture/addendum-technical-references-epic9.md` per pattern implementativi completi:
- asyncpg bulk insert & connection pooling (Sezione 1)
- aiofiles async file I/O (Sezione 2) — **Installazione richiesta**
- Circuit Breaker Pattern (Sezione 3) — Task 3.9-3.12
- Durable Outbox Pattern (Sezione 4) — Task 8
- PostgreSQL FTS Italian (Sezione 5) — Task 2
- PostgreSQL Partial Indices (Sezione 6) — Task 2

### Architettura Persistence Layer

**Pattern**: Hybrid Two-Level Memory Architecture (L1 Cache + L2 Storage)

```
┌────────────────────────────────────────────────────────┐
│         HYBRID CONVERSATIONAL MEMORY                   │
├────────────────────────────────────────────────────────┤
│                                                        │
│   L1 CACHE (In-Memory)    ←→    L2 STORAGE (DB)      │
│   • Last 3 turns                 • Full history       │
│   • <2000 tokens                 • Unlimited          │
│   • Fast <10ms                   • Persistent         │
│   • LLM context                  • Searchable         │
│   • Volatile                     • Archived           │
│                                                        │
│   ┌────────────────────────────────────────────────┐  │
│   │    HybridConversationManager                   │  │
│   │  • Async dual-write (cache + DB)              │  │
│   │  • Cache-first read with DB fallback          │  │
│   │  • Feature flag controlled                    │  │
│   │  • Graceful degradation on DB failure         │  │
│   └────────────────────────────────────────────────┘  │
└────────────────────────────────────────────────────────┘
```

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Architecture Solution"]

### Database Schema & Indices

**Tabella Esistente**: `chat_messages` (già creata, nessuna modifica struttura)

**Nuovi Indici da Creare** (Migration SQL):

```sql
-- Primary query pattern: load session history chronologically
CREATE INDEX idx_chat_messages_session_created 
    ON chat_messages(session_id, created_at DESC);

-- Analytics pattern: recent messages across all sessions
CREATE INDEX idx_chat_messages_created_at 
    ON chat_messages(created_at DESC);

-- Full-text search pattern (Italian language)
CREATE INDEX idx_chat_messages_content_fts 
    ON chat_messages 
    USING GIN (to_tsvector('italian', content));

-- Archive filter pattern: exclude archived sessions
CREATE INDEX idx_chat_messages_metadata_archived
    ON chat_messages((metadata->>'archived'))
    WHERE (metadata->>'archived') IS NOT NULL;
```

**Stima Storage Overhead**: ~2.7MB per 10K messaggi (ben dentro Free Tier Supabase 500MB)

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Database Schema"]

### ConversationPersistenceService Implementation

**Posizione File**: `apps/api/api/services/persistence_service.py` (nuovo file)

**Responsabilità**: Abstract all database persistence operations for chat messages

**Metodi Chiave**:

1. **`save_messages(session_id, messages)`**: 
   - Bulk insert con SQL UNNEST per performance
   - Idempotent: `ON CONFLICT (id) DO NOTHING`
   - Async non-blocking
   - Return bool: True se success, False altrimenti

2. **`load_session_history(session_id, limit, offset, order_desc)`**:
   - Query con INDEX `idx_chat_messages_session_created`
   - Esclude messaggi archived: `WHERE metadata->>'archived' != 'true'`
   - Pagination: limit max 500, default 100
   - Return List[ConversationMessage]

**Query SQL Bulk Insert**:
```sql
INSERT INTO chat_messages (id, session_id, role, content, source_chunk_ids, metadata, created_at)
SELECT * FROM UNNEST($1::uuid[], $2::text[], $3::text[], $4::text[], $5::uuid[][], $6::jsonb[], $7::timestamptz[])
ON CONFLICT (id) DO NOTHING;
```

**Query SQL Load History**:
```sql
SELECT id, session_id, role, content, source_chunk_ids, metadata, created_at
FROM chat_messages
WHERE session_id = $1
  AND (metadata->>'archived' IS NULL OR metadata->>'archived' != 'true')
ORDER BY created_at ASC
LIMIT $2 OFFSET $3;
```

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Component Architecture → ConversationPersistenceService"]

### HybridConversationManager Refactoring

**Pattern**: Estensione di `ConversationManager` (Story 7.1) mantenendo backward compatibility

**Hierarchy**:
```
ConversationManager (existing, Story 7.1)
    ↓ extends
HybridConversationManager (new, Story 9.1)
```

**Costruttore**:
```python
class HybridConversationManager(ConversationManager):
    def __init__(
        self,
        persistence_service: Optional[ConversationPersistenceService] = None,
        enable_persistence: bool = False
    ):
        super().__init__()  # Init L1 cache
        self.persistence = persistence_service
        self.persistence_enabled = enable_persistence
        self._write_tasks: List[asyncio.Task] = []
```

**Metodo `add_turn()` Override**:

Flow:
1. Call `super().add_turn()` → updates in-memory cache (sync, fast)
2. If persistence enabled: async write to DB (non-blocking, fire-and-forget)
3. Track write task per monitoring

```python
def add_turn(self, session_id, user_message, assistant_message, source_chunk_ids=None):
    # L1 cache write (synchronous, fast <5ms)
    super().add_turn(session_id, user_message, assistant_message, source_chunk_ids)
    
    # L2 DB write (asynchronous, non-blocking)
    if self.persistence_enabled and self.persistence:
        messages = self._get_messages_for_session(session_id)
        task = asyncio.create_task(self._async_persist(session_id, messages))
        self._write_tasks.append(task)
```

**Metodo `_async_persist()` Error Handling**:

```python
async def _async_persist(self, session_id, messages):
    try:
        start_time = time.time()
        success = await asyncio.wait_for(
            self.persistence.save_messages(session_id, messages),
            timeout=5.0  # 5s timeout
        )
        latency_ms = (time.time() - start_time) * 1000
        
        if success:
            logger.debug(f"DB persist OK: {session_id}, latency={latency_ms:.0f}ms")
            metrics.increment("db_writes_succeeded")
        else:
            logger.warning(f"DB persist FAILED: {session_id}")
            metrics.increment("db_writes_failed")
        
        metrics.histogram("db_write_latency_ms", latency_ms)
        
    except asyncio.TimeoutError:
        logger.error(f"DB persist TIMEOUT: {session_id}")
        metrics.increment("db_writes_timeout")
    except Exception as e:
        logger.error(f"DB persist ERROR: {session_id}, error={e}")
        metrics.increment("db_writes_error")
```

**Metodo `get_context_window()` Invariato**: 
- Nessuna modifica, mantiene comportamento Story 7.1
- Cache-first, no DB lookup (HOT PATH per latenza chat)

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Component Architecture → HybridConversationManager"]

### Backpressure & Circuit Breaker Implementation

**Bounded Queue Pattern** (Mitigation TECH-001: Async persistence overwhelms DB):

```python
class HybridConversationManager(ConversationManager):
    MAX_PENDING_WRITES = 100  # Bounded queue depth
    
    def add_turn(self, session_id, user_message, assistant_message, source_chunk_ids=None):
        # L1 cache write (synchronous, fast <5ms)
        super().add_turn(session_id, user_message, assistant_message, source_chunk_ids)
        
        # L2 DB write (asynchronous, non-blocking)
        if self.persistence_enabled and self.persistence:
            # BACKPRESSURE: Check queue depth before enqueueing
            if len(self._write_tasks) >= self.MAX_PENDING_WRITES:
                logger.warning({
                    "event": "backpressure_activated",
                    "session_id": session_id,
                    "queue_depth": len(self._write_tasks)
                })
                # Drop oldest pending write (sacrifice completeness for availability)
                dropped_task = self._write_tasks.pop(0)
                dropped_task.cancel()
                metrics.increment("backpressure_activated")
            
            # Enqueue new async write task
            messages = self._get_messages_for_session(session_id)
            task = asyncio.create_task(self._async_persist(session_id, messages))
            self._write_tasks.append(task)
```

**Circuit Breaker Pattern** (Mitigation TECH-001: Protect DB from cascading failures):

```python
class CircuitBreaker:
    """
    Protects DB from overload with circuit breaker pattern.
    
    States:
    - CLOSED: Normal operation, calls pass through
    - OPEN: Failures exceeded threshold, all calls fail fast
    - HALF_OPEN: Testing if service recovered
    
    Transitions:
    - CLOSED → OPEN: failures >= threshold (3)
    - OPEN → HALF_OPEN: timeout expired (30s)
    - HALF_OPEN → CLOSED: success
    - HALF_OPEN → OPEN: failure
    """
    
    def __init__(self, failure_threshold=3, timeout=30):
        self.state = "CLOSED"
        self.failures = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.open_until = None
    
    async def call(self, func, *args, **kwargs):
        """Execute function through circuit breaker."""
        if self.state == "OPEN":
            if time.time() < self.open_until:
                metrics.gauge("circuit_breaker_open", 1)
                raise CircuitBreakerOpenError("Circuit breaker OPEN, failing fast")
            else:
                # Timeout expired, try half-open
                self.state = "HALF_OPEN"
                logger.info("Circuit breaker transitioning to HALF_OPEN")
        
        try:
            result = await func(*args, **kwargs)
            
            # Success: reset or close circuit
            if self.state == "HALF_OPEN":
                self.state = "CLOSED"
                self.failures = 0
                logger.info("Circuit breaker CLOSED after successful call")
                metrics.gauge("circuit_breaker_open", 0)
            
            return result
        
        except Exception as e:
            self.failures += 1
            logger.error({
                "event": "circuit_breaker_failure",
                "failures": self.failures,
                "threshold": self.failure_threshold,
                "error": str(e)
            })
            
            # Trip circuit if threshold exceeded
            if self.failures >= self.failure_threshold:
                self.state = "OPEN"
                self.open_until = time.time() + self.timeout
                logger.error(f"Circuit breaker OPEN for {self.timeout}s")
                metrics.gauge("circuit_breaker_open", 1)
            
            raise


# Integration in HybridConversationManager
class HybridConversationManager(ConversationManager):
    def __init__(self, persistence_service=None, enable_persistence=False):
        super().__init__()
        self.persistence = persistence_service
        self.persistence_enabled = enable_persistence
        self._write_tasks = []
        self.circuit_breaker = CircuitBreaker(failure_threshold=3, timeout=30)
    
    async def _async_persist(self, session_id, messages):
        try:
            start_time = time.time()
            
            # Call through circuit breaker
            success = await self.circuit_breaker.call(
                asyncio.wait_for,
                self.persistence.save_messages(session_id, messages),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            if success:
                logger.debug(f"DB persist OK: {session_id}, latency={latency_ms:.0f}ms")
                metrics.increment("db_writes_succeeded")
            else:
                logger.warning(f"DB persist FAILED: {session_id}")
                metrics.increment("db_writes_failed")
            
            metrics.histogram("db_write_latency_ms", latency_ms)
        
        except CircuitBreakerOpenError:
            logger.warning(f"DB persist SKIPPED (circuit breaker OPEN): {session_id}")
            metrics.increment("db_writes_circuit_breaker_open")
        
        except asyncio.TimeoutError:
            logger.error(f"DB persist TIMEOUT: {session_id}")
            metrics.increment("db_writes_timeout")
        
        except Exception as e:
            logger.error(f"DB persist ERROR: {session_id}, error={e}")
            metrics.increment("db_writes_error")
```

[Fonte: Martin Fowler Circuit Breaker Pattern — https://martinfowler.com/bliki/CircuitBreaker.html]

### Durable Outbox Pattern Implementation

**Purpose**: Guarantee eventual consistency anche durante DB outages prolungati (Mitigation DATA-001: Message loss gaps).

**Architecture**:
```
┌────────────────────────────────────────────────┐
│ DURABLE OUTBOX PATTERN                         │
├────────────────────────────────────────────────┤
│                                                │
│  HybridConversationManager                     │
│           │                                    │
│           ├─ DB Write Success → Done           │
│           │                                    │
│           └─ DB Write Failure ─┐              │
│                                 ↓              │
│                    OutboxPersistenceQueue      │
│                    • .data/persistence_outbox  │
│                    • Append-only JSONL         │
│                    • Idempotency keys          │
│                                 │              │
│                                 ↓              │
│                    Retry Loop (background)     │
│                    • Exponential backoff       │
│                    • Max 10 attempts           │
│                                 │              │
│                    ┌────────────┴─────────┐   │
│                    ↓                      ↓   │
│              DB Recovered          Dead-Letter│
│              → Success             Queue (DLQ)│
│              → Remove from         → Manual   │
│                 outbox               Review   │
└────────────────────────────────────────────────┘
```

**OutboxPersistenceQueue Implementation**:

```python
import hashlib
import json
import time
from pathlib import Path
from typing import List
import aiofiles
from datetime import datetime

class OutboxPersistenceQueue:
    """
    Durable outbox for guaranteed eventual persistence.
    
    Features:
    - Append-only JSONL log (crash-safe)
    - Idempotency keys prevent duplicates
    - Exponential backoff retry (1s → 60s max)
    - Dead-letter queue after 10 failures
    """
    
    def __init__(self, outbox_path=".data/persistence_outbox.jsonl", dlq_path=".data/persistence_dlq.jsonl"):
        self.outbox_path = Path(outbox_path)
        self.dlq_path = Path(dlq_path)
        
        # Ensure data directory exists
        self.outbox_path.parent.mkdir(parents=True, exist_ok=True)
        self.dlq_path.parent.mkdir(parents=True, exist_ok=True)
    
    async def append(self, session_id: str, messages: List[ConversationMessage]):
        """
        Append message batch to durable outbox.
        
        Called when DB write fails to ensure eventual persistence.
        """
        entry = {
            "id": self._generate_idempotency_key(session_id, messages),
            "session_id": session_id,
            "messages": [m.dict() for m in messages],
            "timestamp": datetime.utcnow().isoformat(),
            "retry_count": 0,
            "first_failure_at": datetime.utcnow().isoformat()
        }
        
        # Append-only write (crash-safe)
        async with aiofiles.open(self.outbox_path, mode='a') as f:
            await f.write(json.dumps(entry) + '\n')
        
        logger.info({
            "event": "outbox_append",
            "session_id": session_id,
            "message_count": len(messages),
            "idempotency_key": entry["id"]
        })
        metrics.increment("outbox_appends_total")
    
    def _generate_idempotency_key(self, session_id: str, messages: List[ConversationMessage]) -> str:
        """
        Generate deterministic idempotency key to prevent duplicates.
        
        Key components:
        - session_id: Uniqueness per session
        - timestamp: First message timestamp
        - content_hash: SHA256 of first message content
        
        This ensures same batch retried produces same ID.
        """
        first_msg = messages[0]
        content_hash = hashlib.sha256(
            f"{session_id}:{first_msg.timestamp}:{first_msg.content}".encode()
        ).hexdigest()
        
        return f"{session_id}:{content_hash[:16]}"
    
    async def retry_pending(self):
        """
        Background task: retry all pending outbox entries with exponential backoff.
        
        Runs periodically (e.g., every 5 seconds) to process pending writes.
        """
        if not self.outbox_path.exists():
            return
        
        # Read all pending entries
        async with aiofiles.open(self.outbox_path, mode='r') as f:
            content = await f.read()
        
        if not content.strip():
            return
        
        lines = content.strip().split('\n')
        pending = []
        
        for line in lines:
            entry = json.loads(line)
            
            # Calculate exponential backoff delay
            backoff_seconds = min(2 ** entry['retry_count'], 60)  # Max 60s
            time_since_failure = time.time() - datetime.fromisoformat(entry['timestamp']).timestamp()
            
            if time_since_failure < backoff_seconds:
                # Too early to retry, keep in pending
                pending.append(entry)
                continue
            
            # Attempt retry
            try:
                messages = [ConversationMessage(**m) for m in entry['messages']]
                success = await self.persistence.save_messages(entry['session_id'], messages)
                
                if success:
                    logger.info({
                        "event": "outbox_retry_success",
                        "session_id": entry['session_id'],
                        "idempotency_key": entry['id'],
                        "retry_count": entry['retry_count']
                    })
                    metrics.increment("outbox_retry_success")
                    # Success: remove from outbox (don't re-add to pending)
                else:
                    # Failed but no exception, increment retry and keep pending
                    entry['retry_count'] += 1
                    entry['timestamp'] = datetime.utcnow().isoformat()
                    pending.append(entry)
                    metrics.increment("outbox_retry_failure")
            
            except Exception as e:
                entry['retry_count'] += 1
                entry['timestamp'] = datetime.utcnow().isoformat()
                
                logger.error({
                    "event": "outbox_retry_error",
                    "session_id": entry['session_id'],
                    "retry_count": entry['retry_count'],
                    "error": str(e)
                })
                
                # Dead-letter queue after 10 failures
                if entry['retry_count'] >= 10:
                    await self._move_to_dlq(entry)
                    logger.error({
                        "event": "outbox_dlq",
                        "session_id": entry['session_id'],
                        "idempotency_key": entry['id']
                    })
                    metrics.increment("dlq_messages_total")
                else:
                    pending.append(entry)
        
        # Rewrite outbox with only pending entries (compact on success)
        async with aiofiles.open(self.outbox_path, mode='w') as f:
            for entry in pending:
                await f.write(json.dumps(entry) + '\n')
        
        metrics.gauge("outbox_queue_depth", len(pending))
        
        if len(pending) > 0:
            logger.info({
                "event": "outbox_retry_cycle_complete",
                "pending_count": len(pending),
                "max_retry_count": max(e['retry_count'] for e in pending) if pending else 0
            })
    
    async def _move_to_dlq(self, entry: dict):
        """Move entry to dead-letter queue for manual review."""
        entry['moved_to_dlq_at'] = datetime.utcnow().isoformat()
        
        async with aiofiles.open(self.dlq_path, mode='a') as f:
            await f.write(json.dumps(entry) + '\n')


# Integration in HybridConversationManager
async def _async_persist(self, session_id, messages):
    try:
        # ... existing circuit breaker code ...
        
        if success:
            # Success path unchanged
            pass
    
    except Exception as e:
        # FALLBACK: Append to durable outbox for retry
        if self.outbox_queue:
            await self.outbox_queue.append(session_id, messages)
            logger.warning({
                "event": "persistence_fallback_outbox",
                "session_id": session_id
            })
        
        # Continue raising exception for metrics
        raise
```

**Background Retry Loop** (in main.py or startup):

```python
import asyncio

async def outbox_retry_worker(outbox_queue: OutboxPersistenceQueue):
    """Background task for processing outbox retry queue."""
    while True:
        try:
            await outbox_queue.retry_pending()
        except Exception as e:
            logger.error(f"Outbox retry worker error: {e}")
        
        await asyncio.sleep(5)  # Run every 5 seconds


# In app startup
@app.on_event("startup")
async def startup():
    if settings.enable_persistent_memory:
        outbox_queue = OutboxPersistenceQueue()
        asyncio.create_task(outbox_retry_worker(outbox_queue))
```

[Fonte: Pattern standard Outbox per eventual consistency — Microservices Patterns by Chris Richardson]

### Feature Flag Configuration

**File**: `apps/api/api/core/config.py`

**Settings Field**:
```python
from pydantic import Field
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # ... existing settings ...
    
    # Epic 9: Persistent Memory Feature Flag
    enable_persistent_memory: bool = Field(
        default=False,
        env="ENABLE_PERSISTENT_MEMORY",
        description="Enable long-term conversation memory persistence to database"
    )
```

**Environment Variable**: `.env` e `.env.example`
```bash
# Epic 9 - Persistent Conversational Memory
ENABLE_PERSISTENT_MEMORY=false  # Set true to enable database persistence
```

**Factory Initialization** (`apps/api/api/main.py` o `api/dependencies.py`):
```python
from api.services.conversation_service import HybridConversationManager
from api.services.persistence_service import ConversationPersistenceService

settings = get_settings()

# Initialize persistence service if enabled
persistence_service = None
if settings.enable_persistent_memory:
    persistence_service = ConversationPersistenceService(db_pool=get_db_pool())

# Initialize conversation manager
conv_manager = HybridConversationManager(
    persistence_service=persistence_service,
    enable_persistence=settings.enable_persistent_memory
)
```

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Feature Flag Integration"]

### Graceful Degradation Strategy

**Scenario 1: Database Unavailable**

Behavior:
1. `add_turn()` succeeds (L1 cache write sempre funziona)
2. Async DB write fails → logged as error
3. Metrics incremented: `db_writes_failed`
4. Chat functionality continues uninterrupted (zero user impact)
5. System operates in in-memory only mode

Recovery: Quando DB restored, nuovi messaggi persistono normally. Historical gap remains.

**Scenario 2: Feature Flag Disabled**

Behavior:
1. `HybridConversationManager` initialized senza persistence service
2. All operations use L1 cache only (identico a Story 7.1)
3. Zero breaking changes, instant rollback capability

**Scenario 3: DB Write Latency Spike**

Behavior:
1. Async writes queue up (non-blocking)
2. If queue depth >100 tasks → log warning
3. Chat latency unaffected (async design protects hot path)
4. Monitor for DB scaling needs

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Failure Modes & Graceful Degradation"]

### Performance Targets

**Read Operations**:
- `get_context_window()` (L1 cache): <10ms target (HOT PATH)
- `load_full_history()` (L2 DB): <500ms p95 (indexed query, paginated)

**Write Operations**:
- `add_turn()` L1 write: <5ms (in-memory update, blocking)
- `add_turn()` L2 write: N/A (async, non-blocking)
- DB persist completion: <100ms p95 (background task)

**Cache Performance**:
- Cache Hit Rate target: >95% (per active sessions)
- Cache Miss Penalty: <500ms (DB fallback query)
- Memory Overhead: ~2KB per active session (~200 sessions = 400KB total)

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Performance Characteristics"]

### Monitoring Metrics

**Performance Metrics**:
```python
metrics.histogram("db_write_latency_ms", latency)
metrics.histogram("db_read_latency_ms", latency)
```

**Success/Failure Counters**:
```python
metrics.increment("db_writes_succeeded")
metrics.increment("db_writes_failed")
metrics.increment("db_writes_timeout")
metrics.increment("cache_hits")
metrics.increment("cache_misses")
```

**Business Metrics**:
```python
metrics.gauge("active_sessions_count", count)
metrics.gauge("persistent_messages_count", count)
metrics.histogram("session_message_count", count)
```

**Alerts Configuration**:
- db_write_failure_rate: >5% per 5min → warning
- db_write_latency_high: p95 >500ms per 10min → warning
- cache_hit_rate_low: <90% per 15min → info

[Fonte: `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Monitoring & Observability"]

### Context da Story Precedente (7.1)

**Existing Implementation** (Story 7.1 - SHORT-TERM memory):
- In-memory storage: `chat_messages_store` dictionary
- Last 3 turns (6 messages) retention
- Token budget: <2000 tokens
- Volatile: perso al riavvio

**Integration Point**: `HybridConversationManager` estende `ConversationManager` preservando TUTTA la logica L1 cache esistente

[Fonte: `docs/architecture/addendum-conversational-memory-patterns.md`, Sezione "Architecture"]

### File Structure

**Nuovi File da Creare**:
```
apps/api/api/services/
├── persistence_service.py           # ConversationPersistenceService (NEW)
├── outbox_queue.py                  # OutboxPersistenceQueue (NEW)
└── conversation_service.py          # HybridConversationManager (MODIFY)

supabase/migrations/
└── YYYYMMDDHHMMSS_epic9_conversational_memory_indices.sql  # DB indices (NEW)

tests/
├── services/
│   ├── test_persistence_service.py         # Unit tests (NEW)
│   └── test_hybrid_conversation_manager.py # Integration tests (NEW)
```

**File da Modificare**:
```
apps/api/api/core/config.py          # Add enable_persistent_memory field
.env                                  # Add ENABLE_PERSISTENT_MEMORY
.env.example                          # Add ENABLE_PERSISTENT_MEMORY with comment
```

[Fonte: `docs/architecture/sezione-7-struttura-unificata-del-progetto.md`]

### Testing

**Strategia Testing**:
- Unit test coverage minimo: 80% (per `ConversationPersistenceService`, `HybridConversationManager`)
- Framework: `Pytest` (async tests con `@pytest.mark.anyio`)
- Mocking: `asyncpg.Pool` per DB operations, `monkeypatch` per external dependencies

**Test Patterns Backend** (Pytest + HTTPX):
- Test async con `@pytest.mark.anyio` e `httpx.AsyncClient(app=app, base_url="http://test")`
- Gestire startup/shutdown con `asgi_lifespan.LifespanManager(app)`
- Fixture client riutilizzabile scope `module` per ridurre overhead

**Unit Tests Chiave**:
1. `test_save_messages_bulk_insert()`: Verify bulk insert con UNNEST
2. `test_load_session_history_pagination()`: Verify pagination logic
3. `test_add_turn_dual_write()`: Verify L1 cache + async L2 DB
4. `test_graceful_degradation_db_unavailable()`: Mock DB error → verify fallback

**Integration Tests Chiave**:
1. `test_hybrid_memory_end_to_end()`: Write → wait → read from DB → verify
2. `test_db_write_latency()`: 100 samples → verify p95 <100ms
3. `test_backward_compatibility_flag_off()`: Verify Story 7.1 behavior preserved

[Fonti: `docs/architecture/sezione-11-strategia-di-testing.md`, Sezione "Backend (Pytest + HTTPX)"; `docs/architecture/addendum-persistent-conversational-memory.md`, Sezione "Testing Strategy"]

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-06 | 1.0 | Initial story draft creation | Bob (Scrum Master) |
| 2025-11-06 | 1.1 | Integrated QA critical risk mitigations: AC2 enhanced (backpressure + circuit breaker), NEW AC9 (durable outbox + retry), AC7 enhanced (5 new metrics), Task 3 expanded (subtasks 3.8-3.12), NEW Task 8 (outbox implementation), Dev Notes expanded (backpressure, circuit breaker, outbox patterns). Revised effort: 19-23h (from 12-15h). Risk mitigation: TECH-001 (async overwhelm), DATA-001 (message loss) | Bob (Scrum Master) |
| 2025-11-06 | 1.2 | QA risk/test design review adjustments: Task 1.2 enhanced con explicit idempotency key formula `sha256(session_id + timestamp_ms + content_hash)`, Task 2.2 aggiunto 5° indice UNIQUE su idempotency_key per DB-level enforcement anti-duplicazione. Allineamento dettagliato con DATA-001 (perdita/duplicazione messaggi), IDMP-001 (collisione chiavi). No effort change (già incluso in 19-23h buffer). | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
_To be populated during implementation_

### Debug Log References
_To be populated during implementation_

### Completion Notes List
_To be populated during implementation_

### File List
_To be populated during implementation_

## QA Results
_To be populated after implementation review_

