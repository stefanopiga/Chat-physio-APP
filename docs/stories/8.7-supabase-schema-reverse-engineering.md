# Story 8.7 - Supabase Schema Reverse Engineering

**Data**: 11 Novembre 2025  
**Autore**: Team FisioRAG  
**Stato**: Draft  
**Priorit√†**: Alta  

---

## Contesto e Problema

### Situazione Attuale

La cartella `supabase/migrations/` contiene 10 file di migrazione incrementali:
- `20250922000000_create_document_chunks.sql`
- `20251004000000_create_documents_table.sql`
- `20251005000000_fix_orphan_chunks.sql`
- `20251008000000_create_student_tokens_and_refresh.sql`
- `20251009000000_create_test_users_table.sql`
- `20251013000000_security_performance_hardening.sql`
- `20251030000000_create_feedback_table.sql`
- `20251030120000_grant_feedback_service_role.sql`
- `FIX_GRANT_STUDENT_TOKENS.sql`
- `README_MIGRATION_20251004.md`

### Problema Identificato

**Incertezza sulla correttezza delle migrations**:
1. File migrations scritti manualmente in momenti diversi
2. Possibili inconsistenze tra files (ordine applicazione, dipendenze)
3. Hotfix applicati (`FIX_GRANT_STUDENT_TOKENS.sql`) potrebbero non essere completi
4. Data migrations (`fix_orphan_chunks`) potrebbero mascherare problemi schema
5. **Rischio**: Utenti che clonano repository e applicano migrations potrebbero incontrare errori

### Obiettivo

**Generare schema database consolidato e garantito corretto** tramite reverse engineering del database production attualmente funzionante, usando Supabase CLI.

**Benefici**:
- Schema garantito identico al database production
- Elimina rischio errori da migrations incrementali
- Semplifica setup per nuovi utenti
- Fornisce reference authoritative per schema database

---

## Soluzione Proposta

### Approccio: Reverse Engineering via Supabase CLI

Invece di unire manualmente i file migrations esistenti, interrogare il database production usando Supabase CLI per ottenere schema completo e validato.

### Comandi Supabase CLI Disponibili

**Opzione 1: `supabase db dump`**
- Genera dump completo schema + dati
- Output: SQL standard PostgreSQL
- Include: tabelle, indici, funzioni, trigger, policies RLS, GRANT

**Opzione 2: `supabase db pull`**
- Genera migration file da schema remoto
- Output: File migration in `supabase/migrations/`
- Formato: Migration incrementale

**Scelta raccomandata**: `supabase db dump` per schema consolidato completo.

---

## Passi Operativi

### Prerequisiti

```powershell
# 1. Supabase CLI installato e configurato
C:\Users\user\scoop\shims\supabase.exe --version
# Output atteso: 2.58.5+
# ‚ö†Ô∏è IMPORTANTE: Pinned version requirement
# Questa storia √® testata con CLI version 2.58.5
# Versioni diverse potrebbero generare SQL con sintassi differente

# 2. Autenticazione e link progetto
C:\Users\user\scoop\shims\supabase.exe login
C:\Users\user\scoop\shims\supabase.exe link --project-ref <your-project-ref>

# 3. ‚ö†Ô∏è CRITICO: Verifica connection string DIRECT (porta 5432)
# Dashboard ‚Üí Settings ‚Üí Database ‚Üí Connection string ‚Üí Direct connection
# Formato: postgresql://postgres.<ref>:[PASSWORD]@aws-X-eu-central-2.pooler.supabase.com:5432/postgres
#                                                                                        ^^^^^ DEVE essere porta 5432
# ‚ùå NON usare pooled connection (porta 6543) per dump - generer√† errori
```

**‚ö†Ô∏è Security Checklist Prerequisiti**:
- [ ] Connection string √® Direct (porta 5432, NON 6543)
- [ ] Database source √® production/authoritative
- [ ] CLI version pinned e documentato (2.58.5+)

### Step 1: Dump Schema Completo dal Database Production

```powershell
# Navigare nella cartella supabase/
cd C:\Users\user\Desktop\Claude-Code\fisio-rag-master\APPLICAZIONE\supabase

# ‚ö†Ô∏è CRITICAL: Record CLI version in metadata
C:\Users\user\scoop\shims\supabase.exe --version > sql_unico/.cli_version.txt

# Dump schema completo (senza dati)
C:\Users\user\scoop\shims\supabase.exe db dump --db-url "postgresql://postgres.<ref>:[PASSWORD]@<host>:5432/postgres" --schema public --schema extensions > sql_unico/00_consolidated_schema_GENERATED.sql

# Opzioni spiegate:
# --db-url: Direct connection (porta 5432, NON pooled) ‚ö†Ô∏è CRITICO
# --schema public: Schema principale applicazione
# --schema extensions: Include PGVector extension
# > file.sql: Redirect output su file

# ‚ö†Ô∏è SECURITY: Immediate verification (MUST-DO)
# Verifica 1: NO data statements (hard stop se fallisce)
Select-String -Path sql_unico/00_consolidated_schema_GENERATED.sql -Pattern "(INSERT INTO|COPY )" -CaseSensitive
# Output atteso: NESSUN match trovato
# ‚ùå Se trova match ‚Üí STOP IMMEDIATELY - dump contiene dati!

# Verifica 2: Schema-only content check
Get-Content sql_unico/00_consolidated_schema_GENERATED.sql | Select-String -Pattern "^CREATE (TABLE|INDEX|FUNCTION|EXTENSION|TRIGGER)" | Measure-Object
# Output atteso: > 20 CREATE statements

# Verifica 3: NO secrets/credentials pattern scan
Select-String -Path sql_unico/00_consolidated_schema_GENERATED.sql -Pattern "(password|secret|api_key|token.*=.*'[A-Za-z0-9]{20,}')" -CaseSensitive
# Output atteso: NESSUN match (o solo nomi colonne, non valori)
```

**‚ö†Ô∏è HARD STOP CONDITIONS** (se presenti, NON procedere):
- Presenza di `INSERT INTO` o `COPY` statements ‚Üí Dump contiene dati
- Presenza di credentials/secrets in stringhe ‚Üí Rischio esposizione
- File size > 100KB ‚Üí Possibile inclusione dati

**Output atteso**: File SQL contenente SOLO DDL:
- `CREATE EXTENSION` statements
- `CREATE TABLE` per tutte le tabelle
- `CREATE INDEX` inclusi HNSW indexes
- `CREATE FUNCTION` per stored procedures
- `CREATE TRIGGER` per auto-update timestamps
- `ALTER TABLE` per foreign keys
- `ALTER TABLE` per RLS policies
- `GRANT` statements per permessi

**Metadata Header** (aggiungere manualmente all'inizio file):
```sql
-- ============================================
-- Supabase FisioRAG - Consolidated Schema
-- Generated via Reverse Engineering
-- Date: 2025-11-11
-- Source: Production Database (verified)
-- Supabase CLI Version: 2.58.5
-- Connection: Direct (port 5432)
-- ‚ö†Ô∏è SCHEMA-ONLY: No data included
-- ============================================
```

### Step 2: Pulizia e Validazione Output

```powershell
# Aprire file generato per review manuale
code sql_unico/00_consolidated_schema_GENERATED.sql
```

**Verifica manuale** (checklist obbligatoria):

- [ ] **Extension PGVector** presente:
  ```sql
  CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA extensions;
  ```
  ‚ö†Ô∏è Deve essere in schema `extensions`, NON `public`

- [ ] **Tutte le tabelle** presenti (6 richieste):
  - `documents`
  - `document_chunks`
  - `student_tokens`
  - `refresh_tokens`
  - `users`
  - `feedback` (se presente in production)

- [ ] **Indici HNSW** per embeddings:
  ```sql
  CREATE INDEX document_chunks_embedding_hnsw_idx 
  ON document_chunks USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);
  ```
  ‚ö†Ô∏è Parametri `m` e `ef_construction` devono essere presenti

- [ ] **Foreign Keys** corrette (minimo 3 richieste):
  ```sql
  ALTER TABLE document_chunks 
  ADD CONSTRAINT document_chunks_document_id_fkey 
  FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE;
  
  ALTER TABLE student_tokens
  ADD CONSTRAINT student_tokens_created_by_id_fkey
  FOREIGN KEY (created_by_id) REFERENCES users(id);
  
  ALTER TABLE refresh_tokens
  ADD CONSTRAINT refresh_tokens_token_id_fkey
  FOREIGN KEY (token_id) REFERENCES student_tokens(id) ON DELETE CASCADE;
  ```

- [ ] **‚ö†Ô∏è CRITICAL: RLS Policies** abilitate e presenti per tabelle sensibili:
  ```sql
  -- RLS deve essere ENABLED per queste tabelle:
  ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
  ALTER TABLE document_chunks ENABLE ROW LEVEL SECURITY;
  ALTER TABLE student_tokens ENABLE ROW LEVEL SECURITY;
  ALTER TABLE refresh_tokens ENABLE ROW LEVEL SECURITY;
  
  -- Policies devono essere presenti (nomi possono variare):
  CREATE POLICY "admin_all" ON documents FOR ALL TO authenticated 
    USING (auth.jwt()->>'role' = 'admin');
  -- ... altre policies
  ```
  ‚ö†Ô∏è Se RLS statements mancano ‚Üí HARD STOP, schema incompleto

- [ ] **GRANT statements** per `service_role` (obbligatori):
  ```sql
  GRANT USAGE ON SCHEMA public TO service_role;
  GRANT ALL ON ALL TABLES IN SCHEMA public TO service_role;
  GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO service_role;
  GRANT ALL ON ALL FUNCTIONS IN SCHEMA public TO service_role;
  ```
  ‚ö†Ô∏è Senza questi GRANT, applicazioni backend falliranno

- [ ] **Funzioni stored** presenti (3 richieste):
  - `match_document_chunks()` - Ricerca semantica vettoriale
  - `update_updated_at_column()` - Trigger utility
  - `populate_document_id_from_metadata()` - Auto-popolazione metadata

- [ ] **Trigger** presenti:
  - Trigger su `documents.updated_at`
  - Trigger su `student_tokens.updated_at`
  
- [ ] **‚ö†Ô∏è SECURITY: No production identifiers**:
  - Nessun project ref hard-coded
  - Nessun hostname/URL production
  - Nessuna password o credential literal

### Step 3: Pulizia SQL (Rimozione Elementi Superflui)

**Elementi da rimuovere** (se presenti nel dump):

1. **Commenti auto-generati**:
   ```sql
   --
   -- PostgreSQL database dump
   -- Dumped from database version 15.x
   ```

2. **Statement SET** temporanei:
   ```sql
   SET statement_timeout = 0;
   SET lock_timeout = 0;
   ```

3. **Search path settings** (se causano problemi):
   ```sql
   SET search_path = public, pg_catalog;
   ```

4. **Dati di test** (se inclusi per errore):
   ```sql
   INSERT INTO documents VALUES (...);  -- Rimuovere se presente
   ```

**Mantenere**:
- Tutti i `CREATE` statements
- Tutti gli `ALTER TABLE` per constraints
- Tutti i `GRANT` statements
- Tutte le RLS policies
- Tutte le funzioni e trigger

### Step 4: Test Schema Generato su Database Vuoto

**Creare database test locale**:

```powershell
# Avviare stack Supabase locale
C:\Users\user\scoop\shims\supabase.exe start

# Attendere avvio completo (~30 secondi)
# Output mostra: DB URL: postgresql://postgres:postgres@localhost:54322/postgres

# Applicare schema generato
psql "postgresql://postgres:postgres@localhost:54322/postgres" -f sql_unico/00_consolidated_schema_GENERATED.sql

# Verificare applicazione corretta
psql "postgresql://postgres:postgres@localhost:54322/postgres" -c "
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public'
ORDER BY table_name;
"

# Output atteso:
# document_chunks
# documents
# feedback
# refresh_tokens
# student_tokens
# users
```

**Test funzioni**:

```sql
-- Test match_document_chunks function
SELECT match_document_chunks(
  array_fill(0.1, ARRAY[1536])::vector(1536),
  0.5,
  5
);
-- Output atteso: Empty result set (nessun dato, ma funzione esiste e funziona)
```

**Test indici**:

```sql
-- Verifica HNSW index
SELECT indexname, indexdef 
FROM pg_indexes 
WHERE tablename = 'document_chunks' 
  AND indexname LIKE '%hnsw%';

-- Output atteso:
-- document_chunks_embedding_hnsw_idx | CREATE INDEX...
```

**‚ö†Ô∏è CRITICAL: Test RLS policies** (obbligatorio):

```sql
-- Verifica RLS abilitato per tabelle sensibili
SELECT tablename, rowsecurity 
FROM pg_tables 
WHERE schemaname = 'public' 
  AND tablename IN ('documents', 'document_chunks', 'student_tokens', 'refresh_tokens');

-- Output atteso: rowsecurity = true per TUTTE (4 rows)
-- ‚ùå Se qualche tabella ha rowsecurity = false ‚Üí HARD STOP

-- Verifica policies presenti
SELECT schemaname, tablename, policyname, cmd, qual
FROM pg_policies
WHERE schemaname = 'public'
  AND tablename IN ('documents', 'document_chunks', 'student_tokens', 'refresh_tokens')
ORDER BY tablename, policyname;

-- Output atteso: Almeno 1 policy per tabella
-- Policies tipiche: admin_all, admin_select, students_read_own, etc.
```

**Test GRANT statements**:

```sql
-- Verifica permessi service_role su tutte le tabelle
SELECT grantee, privilege_type, table_name
FROM information_schema.table_privileges 
WHERE table_schema = 'public'
  AND grantee = 'service_role'
  AND table_name IN ('documents', 'document_chunks', 'student_tokens', 'refresh_tokens', 'users', 'feedback')
ORDER BY table_name, privilege_type;

-- Output atteso: INSERT, SELECT, UPDATE, DELETE per tutte le tabelle
-- ‚ùå Se mancano permessi ‚Üí applicazioni backend falliranno
```

### Step 5: Cleanup Stack Locale e Finalizzazione

```powershell
# Stop stack locale
C:\Users\user\scoop\shims\supabase.exe stop

# Rinominare file generato
mv sql_unico/00_consolidated_schema_GENERATED.sql sql_unico/00_consolidated_schema_v2_VERIFIED.sql

# Backup vecchio schema (se esiste)
mv sql_unico/00_consolidated_schema.sql sql_unico/00_consolidated_schema_v1_BACKUP.sql

# Rimuovi file temporanei
rm sql_unico/.cli_version.txt
```

---

## Pre-Commit Guard e CI/CD Integration

### ‚ö†Ô∏è CRITICAL: Pre-Commit Validation Script

**Creare script di validazione** per prevenire commit di schema con dati o secrets:

**File**: `scripts/validate-schema-dump.ps1`

```powershell
# Validate Schema Dump - Pre-Commit Guard
# Usage: .\scripts\validate-schema-dump.ps1 supabase/sql_unico/00_consolidated_schema_v2_VERIFIED.sql

param(
    [Parameter(Mandatory=$true)]
    [string]$SchemaFile
)

Write-Host "üîç Validating schema dump: $SchemaFile" -ForegroundColor Cyan

$errors = @()

# Check 1: File exists
if (-not (Test-Path $SchemaFile)) {
    Write-Host "‚ùå FAIL: File not found" -ForegroundColor Red
    exit 1
}

# Check 2: NO INSERT/COPY statements (data leak)
$dataStatements = Select-String -Path $SchemaFile -Pattern "(INSERT INTO|COPY )" -CaseSensitive
if ($dataStatements) {
    Write-Host "‚ùå CRITICAL: Data statements found!" -ForegroundColor Red
    $dataStatements | ForEach-Object { Write-Host "  Line $($_.LineNumber): $($_.Line)" }
    $errors += "Data statements present"
}

# Check 3: NO secrets pattern
$secretPatterns = Select-String -Path $SchemaFile -Pattern "(password|secret|api_key).*=.*'[A-Za-z0-9]{20,}'" -CaseSensitive
if ($secretPatterns) {
    Write-Host "‚ùå CRITICAL: Potential secrets found!" -ForegroundColor Red
    $secretPatterns | ForEach-Object { Write-Host "  Line $($_.LineNumber): $($_.Line)" }
    $errors += "Secrets detected"
}

# Check 4: Required objects present
$requiredPatterns = @(
    "CREATE EXTENSION.*vector",
    "CREATE TABLE.*documents",
    "CREATE TABLE.*document_chunks",
    "CREATE INDEX.*hnsw",
    "ENABLE ROW LEVEL SECURITY",
    "GRANT.*service_role"
)

foreach ($pattern in $requiredPatterns) {
    $match = Select-String -Path $SchemaFile -Pattern $pattern
    if (-not $match) {
        Write-Host "‚ö†Ô∏è  WARNING: Pattern not found: $pattern" -ForegroundColor Yellow
        $errors += "Missing pattern: $pattern"
    }
}

# Check 5: File size reasonable (< 100KB for schema-only)
$fileSize = (Get-Item $SchemaFile).Length / 1KB
if ($fileSize -gt 100) {
    Write-Host "‚ö†Ô∏è  WARNING: File size ${fileSize}KB > 100KB - possible data inclusion" -ForegroundColor Yellow
    $errors += "File size suspicious: ${fileSize}KB"
}

# Final verdict
if ($errors.Count -gt 0) {
    Write-Host "`n‚ùå VALIDATION FAILED" -ForegroundColor Red
    Write-Host "Errors found: $($errors.Count)" -ForegroundColor Red
    $errors | ForEach-Object { Write-Host "  - $_" }
    exit 1
} else {
    Write-Host "`n‚úÖ VALIDATION PASSED" -ForegroundColor Green
    Write-Host "Schema dump is clean and ready for commit" -ForegroundColor Green
    exit 0
}
```

### Git Pre-Commit Hook (Opzionale)

**File**: `.git/hooks/pre-commit`

```bash
#!/bin/bash
# Pre-commit hook to validate schema dumps

SCHEMA_FILES=$(git diff --cached --name-only | grep "supabase/sql_unico/.*\.sql$")

if [ -n "$SCHEMA_FILES" ]; then
    echo "üîç Validating schema dumps..."
    for file in $SCHEMA_FILES; do
        if ! pwsh -File scripts/validate-schema-dump.ps1 "$file"; then
            echo "‚ùå Pre-commit validation failed for $file"
            echo "Fix errors before committing or use --no-verify to bypass (not recommended)"
            exit 1
        fi
    done
fi

exit 0
```

### CI/CD Job (GitHub Actions esempio)

**File**: `.github/workflows/validate-schema.yml`

```yaml
name: Validate Schema Dump

on:
  pull_request:
    paths:
      - 'supabase/sql_unico/**/*.sql'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Validate Schema Dump
        run: |
          pwsh -File scripts/validate-schema-dump.ps1 supabase/sql_unico/00_consolidated_schema_v2_VERIFIED.sql
      
      - name: Apply to Test DB
        run: |
          # Start local Supabase stack
          npx supabase start
          
          # Apply schema
          psql "postgresql://postgres:postgres@localhost:54322/postgres" -f supabase/sql_unico/00_consolidated_schema_v2_VERIFIED.sql
          
          # Run validation queries
          psql "postgresql://postgres:postgres@localhost:54322/postgres" -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public'"
          
          # Stop stack
          npx supabase stop
```

---

## Validazione Schema Generato vs Production

### Confronto Differenze

```powershell
# Pull schema remoto attuale in migration temporanea
C:\Users\user\scoop\shims\supabase.exe db pull

# Questo genera file in supabase/migrations/<timestamp>_remote_schema.sql

# Confrontare con schema generato
# Tool: VS Code Compare, diff, o Beyond Compare
```

**Differenze attese** (accettabili):
- Ordine statements (non critico)
- Commenti auto-generati
- Formattazione SQL

**Differenze NON accettabili** (richiedono investigazione):
- Tabelle mancanti
- Colonne mancanti o tipo diverso
- Indici mancanti (specialmente HNSW)
- Funzioni mancanti
- GRANT mancanti

### Test Finale: Deploy su Progetto Test

**Creare progetto Supabase test**:

1. Dashboard ‚Üí New Project ‚Üí `fisiorag-test-schema`
2. Attendere provisioning
3. Applicare schema generato:

```powershell
# Via psql
psql "postgresql://postgres.<test-ref>:[PASSWORD]@<host>:5432/postgres" -f sql_unico/00_consolidated_schema_v2_VERIFIED.sql

# Oppure via Dashboard SQL Editor (copia/incolla contenuto file)
```

4. Verificare applicazione corretta (query verifica sezione precedente)
5. **Se successo**: Schema validato ‚úÖ
6. **Se errori**: Investigare e correggere

---

## Output Attesi

### File Generato

**Posizione**: `supabase/sql_unico/00_consolidated_schema_v2_VERIFIED.sql`

**Dimensione stimata**: 15-25 KB (dipende da numero policies RLS)

**Struttura file**:

```sql
-- ============================================
-- Supabase FisioRAG - Consolidated Schema
-- Generated via Reverse Engineering
-- Date: 2025-11-11
-- Source: Production Database (verified)
-- ============================================

-- Extensions
CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA extensions;

-- Tables
CREATE TABLE documents (...);
CREATE TABLE document_chunks (...);
CREATE TABLE student_tokens (...);
CREATE TABLE refresh_tokens (...);
CREATE TABLE users (...);
CREATE TABLE feedback (...);

-- Indexes
CREATE INDEX idx_document_chunks_document_id ON document_chunks(document_id);
CREATE INDEX document_chunks_embedding_hnsw_idx ON document_chunks USING hnsw (...);
-- ... altri indici

-- Functions
CREATE OR REPLACE FUNCTION match_document_chunks(...) RETURNS TABLE(...) AS $$
  -- ...
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION update_updated_at_column() RETURNS TRIGGER AS $$
  -- ...
$$ LANGUAGE plpgsql;

-- Triggers
CREATE TRIGGER update_documents_updated_at 
  BEFORE UPDATE ON documents 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- Foreign Keys
ALTER TABLE document_chunks 
  ADD CONSTRAINT document_chunks_document_id_fkey 
  FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE;

-- Row Level Security
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
CREATE POLICY "admin_all" ON documents FOR ALL TO authenticated 
  USING (auth.jwt()->>'role' = 'admin');

-- ... altre policies

-- Grants
GRANT USAGE ON SCHEMA public TO service_role;
GRANT ALL ON ALL TABLES IN SCHEMA public TO service_role;
GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO service_role;
GRANT ALL ON ALL FUNCTIONS IN SCHEMA public TO service_role;
```

### Documentazione Aggiornata

**Aggiornare** `supabase/README.md` - Sezione "Setup Database Schema":

```markdown
### Metodo 1: Schema Consolidato (Raccomandato) ‚úÖ

**File**: `sql_unico/00_consolidated_schema_v2_VERIFIED.sql`

**Caratteristiche**:
- ‚úÖ Generato tramite reverse engineering da database production
- ‚úÖ Schema validato e testato
- ‚úÖ Include tutte le tabelle, indici, funzioni, policies RLS
- ‚úÖ Garantito identico al database production funzionante

**Applicazione**:

Via Dashboard SQL Editor:
1. Dashboard ‚Üí SQL Editor
2. Copia contenuto file `00_consolidated_schema_v2_VERIFIED.sql`
3. Run (Ctrl+Enter)
4. Verifica successo (nessun errore)

Via CLI:
```powershell
psql "postgresql://postgres.<ref>:[PASSWORD]@<host>:5432/postgres" -f supabase/sql_unico/00_consolidated_schema_v2_VERIFIED.sql
```

**Verifica applicazione**:
```sql
-- Conteggio tabelle (atteso: 6)
SELECT COUNT(*) FROM information_schema.tables 
WHERE table_schema = 'public';
```
```

---

## Rischi e Mitigazioni

### Rischio 1: Dump Include Dati Sensibili

**Probabilit√†**: Bassa (usando `db dump` senza `--data-only`)

**Impatto**: Alto (esposizione credenziali/dati utenti)

**Mitigazione**:
- Usare flag `--schema-only` (implicito in `db dump` senza `--data-only`)
- Review manuale file generato prima di commit
- Verificare assenza `INSERT INTO` statements con dati reali

### Rischio 2: Schema Production Include Oggetti di Test

**Probabilit√†**: Media

**Impatto**: Medio (schema contiene tabelle/funzioni non necessarie)

**Mitigazione**:
- Review manuale post-generazione
- Rimuovere oggetti `_test`, `_temp`, `_backup`
- Confrontare con documentazione schema atteso

### Rischio 3: Dipendenze Esterne Non Catturate

**Probabilit√†**: Bassa (Supabase gestito include tutto)

**Impatto**: Alto (schema non applicabile)

**Mitigazione**:
- Test su database vuoto (Step 4)
- Verificare errori applicazione
- Documentare dipendenze esterne se presenti

### Rischio 4: Schema Generato Troppo Specifico

**Probabilit√†**: Media (include settings specifici production)

**Impatto**: Basso (configurazioni non ottimali per setup locale)

**Mitigazione**:
- Rimuovere `SET` statements temporanei
- Rimuovere configurazioni hardware-specific
- Mantenere solo DDL portable

---

## Checklist Completamento

### ‚ö†Ô∏è CRITICAL - Security & Prerequisites

- [ ] **Prerequisiti verificati**
  - [ ] Supabase CLI versione 2.58.5+ installato
  - [ ] CLI version recorded in `.cli_version.txt`
  - [ ] Autenticato e linkato a progetto production
  - [ ] ‚ö†Ô∏è Connection string √® DIRECT (porta 5432, NON 6543)
  - [ ] Database source verificato essere production/authoritative

### Step 1: Schema Generation

- [ ] **Schema generato**
  - [ ] Comando `supabase db dump --schema public --schema extensions` eseguito
  - [ ] File salvato in `sql_unico/00_consolidated_schema_GENERATED.sql`
  - [ ] ‚ö†Ô∏è HARD STOP: NO INSERT/COPY statements presenti
  - [ ] ‚ö†Ô∏è HARD STOP: NO secrets/credentials pattern detected
  - [ ] Dimensione file < 100KB (schema-only)
  - [ ] Metadata header aggiunto con CLI version e date

### Step 2: Manual Review

- [ ] **Review manuale completata**
  - [ ] Extension PGVector presente in schema `extensions`
  - [ ] Tutte le 6 tabelle presenti (documents, document_chunks, student_tokens, refresh_tokens, users, feedback)
  - [ ] Indice HNSW con parametri m/ef_construction presente
  - [ ] Foreign keys corrette (minimo 3 richieste)
  - [ ] ‚ö†Ô∏è CRITICAL: RLS ENABLED per 4 tabelle sensibili
  - [ ] ‚ö†Ô∏è CRITICAL: RLS policies presenti per tabelle sensibili
  - [ ] ‚ö†Ô∏è CRITICAL: GRANT statements per service_role completi
  - [ ] Funzioni stored presenti (3 richieste: match_document_chunks, update_updated_at_column, populate_document_id_from_metadata)
  - [ ] Trigger presenti (documents.updated_at, student_tokens.updated_at)
  - [ ] Nessun production identifier hard-coded

### Step 3: SQL Cleanup

- [ ] **Pulizia SQL**
  - [ ] Commenti auto-generati rimossi/puliti
  - [ ] SET statements temporanei rimossi
  - [ ] Nessun INSERT statement con dati
  - [ ] Nessun production-specific identifier presente

### Step 4: Test su Database Vuoto

- [ ] **Test applicazione schema**
  - [ ] Stack locale Supabase avviato
  - [ ] Schema applicato via psql senza errori
  - [ ] 6 tabelle create verificate
  - [ ] Extension vector presente
  - [ ] Indice HNSW verificato presente
  - [ ] Funzioni testate (match_document_chunks eseguita)
  - [ ] ‚ö†Ô∏è CRITICAL: RLS enabled verificato per 4 tabelle
  - [ ] ‚ö†Ô∏è CRITICAL: Policies presenti verificate (query pg_policies)
  - [ ] ‚ö†Ô∏è CRITICAL: GRANT service_role verificati completi
  - [ ] Foreign keys verificate (query information_schema.table_constraints)
  - [ ] Stack locale fermato e pulito

### Step 5: Validation vs Production

- [ ] **Validazione vs Production**
  - [ ] `supabase db pull` eseguito per confronto
  - [ ] Differenze analizzate
  - [ ] Differenze cosmetic accettate
  - [ ] Differenze critiche risolte

### Step 6: Test Deploy Progetto Nuovo

- [ ] **Test deploy end-to-end**
  - [ ] Progetto test Supabase creato
  - [ ] Schema applicato con successo
  - [ ] Tutte le verifiche post-deploy completate
  - [ ] Progetto test pu√≤ essere eliminato

### Step 7: Pre-Commit Guard & CI/CD

- [ ] **Automation setup**
  - [ ] Script `validate-schema-dump.ps1` creato
  - [ ] Script eseguito e passato su schema finale
  - [ ] (Opzionale) Git pre-commit hook installato
  - [ ] (Opzionale) CI/CD job configurato

### Final: Finalizzazione

- [ ] **Finalizzazione**
  - [ ] File rinominato in `00_consolidated_schema_v2_VERIFIED.sql`
  - [ ] Backup vecchio schema creato (`v1_BACKUP.sql`)
  - [ ] File temporanei rimossi
  - [ ] README.md aggiornato con istruzioni uso nuovo schema
  - [ ] Metadata `.cli_version.txt` archiviato o documentato

### Documentation

- [ ] **Documentazione**
  - [ ] Questa storia marked as DONE
  - [ ] Changelog aggiornato
  - [ ] Note su differenze vs vecchio schema documentate
  - [ ] Team notificato del nuovo schema availability

---

## Gate Criteria (Based on Risk Profile)

**FAIL ‚Üí CONCERNS**:
- [ ] Schema √® schema-only (NO data statements)
- [ ] NO secrets detected in dump
- [ ] Apply su clean DB succeeded senza errori

**CONCERNS ‚Üí PASS**:
- [ ] RLS policies verified enabled and present
- [ ] GRANT statements verified complete
- [ ] Diff vs production shows NO material gaps
- [ ] Pre-commit validation script passes

---

## Note e Considerazioni

### Gestione Migrations Incrementali Esistenti

**Domanda**: Cosa fare con i file in `supabase/migrations/`?

**Opzioni**:

1. **Conservare per storico** (raccomandato):
   - Spostare in `supabase/migrations/_archive/`
   - Mantenere per reference storia evolutiva schema
   - Non usare per setup nuovi progetti

2. **Eliminare**:
   - Se schema generato √® reference unico
   - Rimuove confusione per nuovi utenti
   - Perdita tracciabilit√† storica

3. **Mantenerle parallele**:
   - README indica schema consolidato come metodo primario
   - Migrations incrementali come alternativa avanzata
   - Maggiore manutenzione

**Scelta raccomandata**: Opzione 1 (archiviazione).

### File sql_unico/ - Gestione Versioni

**Schema attuale**:
- `00_consolidated_schema.sql` (esistente, potenzialmente errato)

**Dopo questa story**:
- `00_consolidated_schema_v1_BACKUP.sql` (backup vecchio)
- `00_consolidated_schema_v2_VERIFIED.sql` (generato e validato)

**Per futuro**:
- Usare `v2_VERIFIED.sql` come reference
- Aggiornare con nuovi `db dump` quando schema cambia
- Incrementare versione: v3, v4, etc.

### Automazione Futura

**Considerare**:
- Script automatico per rigenerazione periodica
- CI/CD job per validare schema vs production
- Alert se schema locale diverge da remoto

**Esempio script** (`scripts/regenerate-schema.ps1`):
```powershell
# Regenerate consolidated schema from production
$PROJECT_REF = $env:SUPABASE_PROJECT_REF
$DB_URL = "postgresql://postgres.$PROJECT_REF:$env:SUPABASE_DB_PASSWORD@...5432/postgres"

C:\Users\user\scoop\shims\supabase.exe db dump `
  --db-url $DB_URL `
  --schema public `
  --schema extensions `
  > supabase/sql_unico/00_consolidated_schema_latest.sql

Write-Host "Schema regenerated successfully"
```

---

## Riferimenti

**Supabase CLI Documentation**:
- [db dump command](https://supabase.com/docs/reference/cli/supabase-db-dump)
- [db pull command](https://supabase.com/docs/reference/cli/supabase-db-pull)
- [Database Migrations Guide](https://supabase.com/docs/guides/cli/local-development#database-migrations)

**PostgreSQL Documentation**:
- [pg_dump](https://www.postgresql.org/docs/current/app-pgdump.html)
- [Schema Dump Best Practices](https://wiki.postgresql.org/wiki/Schema_Dump)

**File Correlati**:
- `supabase/README.md` - Documentazione principale setup database
- `supabase/sql_unico/` - Cartella schema consolidati
- `supabase/migrations/` - Migrations incrementali (da archiviare)

---

## Tempo Stimato

**Totale**: 90-120 minuti (incrementato per security checks)

**Breakdown**:
- Setup prerequisiti e CLI version pin: 15 min
- Generazione schema + immediate security scans: 10 min
- Review manuale completa (con RLS/GRANT verification): 25 min
- Pulizia SQL: 10 min
- Test su database vuoto (con extended validations): 20 min
- Validazione vs production: 10 min
- Deploy test e verifica: 15 min
- Pre-commit guard script creation: 10 min
- Documentazione e finalizzazione: 15 min

---

## Success Criteria

1. ‚úÖ File `00_consolidated_schema_v2_VERIFIED.sql` generato
2. ‚úÖ Schema applicabile su database vuoto senza errori
3. ‚úÖ Tutte le tabelle, indici, funzioni presenti e funzionanti
4. ‚úÖ RLS policies configurate correttamente
5. ‚úÖ GRANT statements completi
6. ‚úÖ Test su progetto nuovo Supabase superato
7. ‚úÖ README.md aggiornato con istruzioni uso nuovo schema
8. ‚úÖ Nessun dato sensibile presente nel file SQL

**Criterio principale**: Utente che clona repository pu√≤ configurare database completo applicando singolo file SQL senza errori.

---

## ‚úÖ QA Feedback Integration

**Questa storia √® stata aggiornata in base ai feedback di:**
- **PO Validation** (8.7-story-draft-validation-20251111.md) - Assessment: GO with edits
- **Risk Profile** (8.7-supabase-schema-reverse-engineering-risk-20251111.md) - 11 risks identified
- **Test Design** (8.7-test-design-20251111.md) - 20 test scenarios (8 P0)

**Correzioni applicate:**

1. ‚úÖ **CLI Version Pinning** (PO Should-Fix, OPS-873 High Risk)
   - Aggiunto requirement esplicito CLI 2.58.5+
   - Recording version in metadata header
   - Salvato `.cli_version.txt` temporaneo

2. ‚úÖ **Schema-Only Enforcement** (PO Should-Fix, DATA-871 Critical Risk)
   - Aggiunto immediate verification con `Select-String` per INSERT/COPY
   - HARD STOP conditions documentate
   - Pre-commit guard script completo con data leak detection

3. ‚úÖ **Direct Connection Requirement** (PO Should-Fix, OPS-877 Medium Risk)
   - Enfatizzato porta 5432 requirement con warning visivi
   - Forbidden uso pooled connection (6543) per dump
   - Formato connection string esplicito con placeholder

4. ‚úÖ **RLS Verification Checklist** (PO Should-Fix, SEC-878 Medium Risk)
   - Aggiunto checklist RLS enabled per 4 tabelle sensibili
   - Query validation per pg_policies inclusion
   - CRITICAL markers per RLS verification in test step

5. ‚úÖ **Secrets Scan Requirement** (PO Should-Fix, SEC-872 High Risk)
   - Pattern scan per credentials/secrets in Step 1
   - Pre-commit script valida absence di secrets
   - HARD STOP se secrets detected

6. ‚úÖ **GRANT Verification** (DATA-874 High Risk)
   - Extended checklist con GRANT verification
   - Query validation per service_role permissions
   - Warning che senza GRANT backend applications fail

7. ‚úÖ **Pre-Commit Guard** (PO Should-Fix, Test Design 8.7-E2E-002)
   - Script PowerShell completo `validate-schema-dump.ps1`
   - Git hook esempio provided
   - CI/CD job GitHub Actions template

8. ‚úÖ **Test Coverage** (Test Design requirements)
   - Extended test queries per tutte le validations
   - Separate test sections per tables, indexes, functions, triggers, FKs, RLS, GRANTs
   - HARD STOP conditions per failed validations

**Risk Mitigation Coverage:**
- DATA-871 (Critical) ‚Üí Mitigato con schema-only enforcement + pre-commit guard
- SEC-872 (High) ‚Üí Mitigato con secrets pattern scan
- OPS-873 (High) ‚Üí Mitigato con CLI version pinning
- DATA-874 (High) ‚Üí Mitigato con comprehensive object validation
- Altri 7 rischi Medium/Low ‚Üí Mitigati con checklist estese

**Gate Status:**
- Initial Draft ‚Üí CONCERNS (critical risk present)
- After Corrections ‚Üí PASS (all must-fix addressed)

---

## Next Steps (Post-Completamento)

1. Aggiornare CI/CD per usare nuovo schema in test
2. Notificare team del nuovo metodo setup
3. Aggiornare documentazione onboarding
4. Considerare archiviazione migrations incrementali
5. Pianificare processo aggiornamento schema periodico
6. Creare template issue GitHub per segnalazione divergenze schema

