# Story 6.6: Documentation Corrections & Cleanup

**Status:** Draft

## Story

**Come** sviluppatore del sistema,
**voglio** documentazione tecnica accurata e completa con correzioni di imprecisioni minori,
**in modo da** evitare confusione e avere riferimenti affidabili.

## Context

Durante l'analisi di allineamento documentazione-codice (che ha portato alla creazione dell'Epic 6), sono state identificate diverse **imprecisioni minori** e **lacune documentali** che, pur non essendo critiche, causano confusione e riducono l'affidabilit√† della documentazione.

### Problemi Identificati

1. **Separatori LangChain Imprecisi**
   - **Documentato:** `"separators: default Python (newlines, period+space, spaces)"`
   - **Realt√†:** LangChain default `["\n\n", "\n", " ", ""]` (NO period+space)
   - **Impact:** BASSO - funziona comunque, ma documentazione fuorviante

2. **Note "Phase 2" Ambigue**
   - Codice contiene commenti `# OCR caption extraction: Phase 2`
   - Documentazione non chiarisce cosa sia "Phase 2" o quando sar√† implementato
   - **Impact:** MEDIO - genera aspettative poco chiare

3. **Benchmark Scope Non Chiaro**
   - `addendum-chunking-strategy-benchmark.md` non specifica che si riferisce solo a pipeline API
   - Post-6.1, benchmark si applicano a entrambe le pipeline
   - **Impact:** MEDIO - confusione su scope dei risultati

4. **Feature Status Poco Chiaro**
   - Difficile capire quali feature sono MVP vs future enhancements
   - Nessun documento centrale "stato delle feature"
   - **Impact:** MEDIO - aspettative non realistiche

### Obiettivo

Correggere tutte le imprecisioni minori, aggiungere note esplicative dove necessario, e creare un documento centrale sullo stato delle feature per trasparenza completa.

## Acceptance Criteria

### AC1: Separatori LangChain Documentati Correttamente
- [ ] Identificati tutti i riferimenti ai separatori nella documentazione
- [ ] Sostituito "default Python (newlines, period+space, spaces)" con "LangChain default (`["\n\n", "\n", " ", ""]`)"
- [ ] Nota esplicativa: "Period+space non incluso per evitare split mid-sentence"
- [ ] Verificato che codice corrisponda a documentazione aggiornata

### AC2: Note "Phase 2" Chiarite
- [ ] Creato documento `docs/architecture/feature-roadmap.md` con:
  - **MVP Features:** Cosa √® implementato ora
  - **Phase 2 Features:** Cosa √® pianificato (con Issue links)
  - **Future Enhancements:** Idee non ancora pianificate
- [ ] Sostituiti commenti `# Phase 2` nel codice con link a feature-roadmap:
  ```python
  # Planned enhancement: OCR caption extraction (see docs/architecture/feature-roadmap.md#phase-2)
  ```
- [ ] Tabella chiara: Feature √ó Status (MVP / Phase 2 / Future)

### AC3: Benchmark Documentation Aggiornato
- [ ] Sezione "Implementation Notes" aggiunta a `addendum-chunking-strategy-benchmark.md`:
  ```markdown
  ## Implementation Notes
  
  **Pipeline Scope (Pre-Story 6.1):**
  - Benchmark results reflect API pipeline (`POST /admin/knowledge-base/sync-jobs`)
  - Watcher pipeline used basic extraction + fallback chunking only
  
  **Pipeline Scope (Post-Story 6.1):**
  - Benchmark results apply to BOTH pipelines (watcher + API)
  - Unified extraction and classification across all ingestion modes
  
  For pipeline comparison, see: [Ingestion Pipelines Comparison](ingestion-pipelines-comparison.md)
  ```
- [ ] Link a Story 6.1 per contesto storico

### AC4: Feature Status Dashboard Creato
- [ ] Creato `docs/architecture/feature-status.md` con:
  - **Executive Summary:** High-level stato del sistema
  - **Core Pipeline Features:** Extraction, Classification, Chunking, Indexing
  - **RAG Features:** Retrieval, Generation, Citations
  - **Infrastructure:** Caching, Monitoring, Security
  - Tabella: Feature √ó Status √ó Story √ó Notes
- [ ] Link da `docs/architecture/index.md`
- [ ] Link da README.md principale (se esiste)

### AC5: Documentazione Codice Sorgente Allineata
- [ ] Review docstring di funzioni/classi chiave:
  - `DocumentExtractor.extract()`
  - `classify_content_enhanced()`
  - `ChunkRouter.route()`
  - `scan_once()` (watcher)
- [ ] Docstring include:
  - Parametri con tipi
  - Valori di ritorno
  - Eccezioni raised
  - Esempi d'uso (se complesso)
  - Link a documentazione architetturale
- [ ] Verificato che docstring corrisponda a implementazione attuale

## Tasks / Subtasks

### Task 1: Correggere Riferimenti Separatori LangChain (AC1)
- [ ] Ricerca globale: `grep -r "separators.*default.*Python" docs/`
- [ ] Identificare tutti i file con riferimenti imprecisi
- [ ] Sostituire in ogni file:
  - **Da:** `"separators: default Python (newlines, period+space, spaces)"`
  - **A:** `"separators: LangChain default (["\n\n", "\n", " ", ""])"`
- [ ] Aggiungere nota esplicativa dove rilevante:
  ```markdown
  **Nota:** LangChain non include period+space (`. `) di default per evitare 
  split mid-sentence. Split avviene su paragraph breaks, then line breaks, 
  then spaces, garantendo chunk semanticamente coerenti.
  ```
- [ ] File probabili da aggiornare:
  - `docs/architecture/addendum-chunking-strategy-benchmark.md`
  - `docs/architecture/addendum-langchain-loaders-splitters.md`
  - Qualsiasi altro riferimento trovato

### Task 2: Creare Feature Roadmap e Chiarire "Phase 2" (AC2)
- [ ] Creare `docs/architecture/feature-roadmap.md`:
  ```markdown
  # Feature Roadmap
  
  ## MVP Features (Implemented)
  
  ### Document Extraction
  - ‚úÖ PDF text extraction (PyMuPDF)
  - ‚úÖ DOCX text + tables extraction (python-docx)
  - ‚úÖ Image metadata detection (count, page, size)
  - ‚úÖ Table structure extraction (headers, rows)
  
  ### Classification & Chunking
  - ‚úÖ LLM-based document classification (OpenAI GPT)
  - ‚úÖ Domain classification (fisioterapia_clinica, anatomia, etc.)
  - ‚úÖ Structure classification (TESTO_ACCADEMICO_DENSO, DOCUMENTO_TABELLARE)
  - ‚úÖ Intelligent chunking routing (RecursiveCharacter vs TabularStructural)
  - ‚úÖ Redis classification caching
  
  ### RAG Pipeline
  - ‚úÖ Semantic search (pgvector + OpenAI embeddings)
  - ‚úÖ Augmented generation (GPT-5-nano)
  - ‚úÖ Citation extraction and formatting
  
  ## Phase 2 Features (Planned)
  
  ### Enhanced Extraction
  - ‚è≥ OCR caption extraction for images (Issue #XXX)
  - ‚è≥ Advanced table parsing with pdfplumber (Issue #XXX)
  - ‚è≥ Chart/diagram recognition and description
  
  ### Advanced Chunking
  - ‚è≥ Semantic chunking based on embeddings (Story 2.X evaluation showed 
       marginal benefit vs 5x cost - deferred)
  - ‚è≥ Contextual overlap optimization (adaptive based on content type)
  
  ### Quality Improvements
  - ‚è≥ Multi-language support (currently Italian only)
  - ‚è≥ Citation confidence scoring
  - ‚è≥ Answer quality feedback loop
  
  ## Future Enhancements (Not Planned Yet)
  
  - üîÆ Video content extraction and indexing
  - üîÆ Audio transcription integration
  - üîÆ Real-time collaborative document editing
  - üîÆ Multi-modal RAG (images + text context)
  ```
- [ ] Aggiornare commenti nel codice:
  - **File:** `apps/api/api/knowledge_base/extractors.py`
  - **Trova:** `# OCR caption extraction: Phase 2`
  - **Sostituisci con:** `# Planned: OCR caption extraction (see docs/architecture/feature-roadmap.md#phase-2-enhanced-extraction)`
  - Ripeti per tutti i commenti "Phase 2"
- [ ] Aggiungere link da `docs/architecture/index.md`

### Task 3: Aggiornare Benchmark Documentation (AC3)
- [ ] Aprire `docs/architecture/addendum-chunking-strategy-benchmark.md`
- [ ] Individuare posizione ottimale per sezione (prima di "## Benchmark Retrieval")
- [ ] Inserire sezione "Implementation Notes":
  ```markdown
  ## Implementation Notes
  
  ### Historical Context
  
  **Pre-Story 6.1 (Jan 2025):**
  - These benchmarks were conducted using the API pipeline (`POST /admin/knowledge-base/sync-jobs`)
  - The watcher pipeline (automatic filesystem ingestion) used basic extraction only
  - Classification and intelligent chunking were exclusive to API uploads
  
  **Post-Story 6.1 (Jan 2025):**
  - Watcher pipeline enhanced with DocumentExtractor and LLM classification
  - Benchmark results now apply to BOTH ingestion pipelines uniformly
  - All documents benefit from optimal chunking regardless of upload method
  
  ### Pipeline Comparison
  
  For detailed comparison of ingestion pipelines and their capabilities, see:
  [Ingestion Pipelines Comparison](ingestion-pipelines-comparison.md)
  
  For integration details, see: **Story 6.1 - Pipeline Documentation & Watcher Enhancement**
  ```
- [ ] Verificare che tutti i riferimenti a "pipeline" siano ora chiari su quale pipeline
- [ ] Aggiungere link a Story 6.1 in changelog del documento

### Task 4: Creare Feature Status Dashboard (AC4)
- [ ] Creare `docs/architecture/feature-status.md`:
  ```markdown
  # Feature Status Dashboard
  
  **Last Updated:** 2025-01-17  
  **Version:** 1.0 (Post-Epic 6)
  
  ## Executive Summary
  
  FisioRAG MVP is **production-ready** with core RAG capabilities fully implemented:
  - ‚úÖ Intelligent document ingestion (PDF, DOCX, TXT)
  - ‚úÖ LLM-powered classification and optimal chunking
  - ‚úÖ Semantic search with high precision (84% P@5)
  - ‚úÖ Augmented generation with accurate citations
  - ‚úÖ Admin dashboard and student access management
  
  ## Core Features Matrix
  
  | Feature | Status | Story | Notes |
  |---------|--------|-------|-------|
  | **Document Extraction** |
  | PDF Text Extraction | ‚úÖ MVP | 2.1, 2.5 | PyMuPDF-based |
  | DOCX Text Extraction | ‚úÖ MVP | 2.1, 2.5 | python-docx |
  | Image Metadata | ‚úÖ MVP | 2.5 | Count, page, size |
  | Table Extraction | ‚úÖ MVP | 2.5 | Structured format |
  | OCR Captions | ‚è≥ Phase 2 | TBD | Requires OCR library |
  | **Classification & Chunking** |
  | LLM Classification | ‚úÖ MVP | 2.2, 2.5 | OpenAI GPT-5-nano |
  | Domain Detection | ‚úÖ MVP | 2.5 | 8 fisioterapia domains |
  | Structure Detection | ‚úÖ MVP | 2.2, 2.5 | 3 structure types |
  | RecursiveCharacter Chunking | ‚úÖ MVP | 2.3, 2.11 | 800/160 optimal |
  | TabularStructural Chunking | ‚úÖ MVP | 2.3 | For structured docs |
  | Classification Cache | ‚úÖ MVP | 2.9 | Redis-backed |
  | Watcher Classification | ‚úÖ MVP | 6.1 | Feature-flagged |
  | Semantic Chunking | ‚ùå Deferred | N/A | Cost vs benefit |
  | **RAG Pipeline** |
  | Semantic Search | ‚úÖ MVP | 3.1, 2.11 | pgvector + OpenAI |
  | Augmented Generation | ‚úÖ MVP | 3.2, 2.11 | GPT-5-nano |
  | Citation Extraction | ‚úÖ MVP | 3.2, 2.11 | LangChain-based |
  | Multi-turn Chat | ‚úÖ MVP | 3.3 | Session management |
  | Source Visualization | ‚úÖ MVP | 3.4 | Frontend citations |
  | **Infrastructure** |
  | Redis Caching | ‚úÖ MVP | 2.9, 4.3 | Classification + rate limiting |
  | Health Monitoring | ‚úÖ MVP | 2.6, 2.8 | P95 validation |
  | Rate Limiting | ‚úÖ MVP | 4.3 | SlowAPI-based |
  | Database Hardening | ‚úÖ MVP | 2.7 | FK constraints, indexes |
  | Docker Deployment | ‚úÖ MVP | 1.1, 2.6 | Multi-container |
  | **Testing & Quality** |
  | Backend Unit Tests | ‚úÖ MVP | 5.x | >85% coverage |
  | Backend Integration Tests | ‚úÖ MVP | 5.x | Supabase mocks |
  | Frontend Unit Tests | ‚úÖ MVP | 5.x | Vitest + RTL |
  | E2E Tests | ‚úÖ MVP | 5.x | Playwright |
  | Security Validation | ‚úÖ MVP | 5.1 | OWASP Top 10 |
  
  ## Phase 2 Roadmap (Not Started)
  
  - ‚è≥ OCR caption extraction
  - ‚è≥ Advanced table parsing (pdfplumber)
  - ‚è≥ Multi-language support
  - ‚è≥ Citation confidence scoring
  
  ## Known Limitations (MVP)
  
  1. **Single Language:** Italian only (domain-specific corpus)
  2. **Document Types:** PDF, DOCX, TXT only (no video/audio)
  3. **Image Processing:** Metadata only, no visual analysis
  4. **Table Parsing:** Basic structure, no complex cell merging
  5. **Classification:** Requires OpenAI API (no offline mode)
  
  ## Version History
  
  - **v1.0 (Epic 6):** Pipeline consolidation, documentation alignment
  - **v0.9 (Epic 5):** Test suite modernization, security hardening
  - **v0.8 (Epic 4):** Admin features, analytics, caching
  - **v0.7 (Epic 3):** RAG activation, chat UI
  - **v0.6 (Epic 2):** Knowledge base pipeline completion
  - **v0.5 (Epic 1):** Foundation, authentication, access control
  ```
- [ ] Aggiungere link da `docs/architecture/index.md`
- [ ] Aggiungere link da `README.md` (se esiste sezione "Features")

### Task 5: Allineare Documentazione Codice Sorgente (AC5)
- [ ] Review e aggiornamento docstring per:
  
  **File: `apps/api/api/knowledge_base/extractors.py`**
  ```python
  class DocumentExtractor:
      """Unified document extraction with image/table support.
      
      Extracts text, images, tables, and metadata from documents for
      intelligent ingestion pipeline. Supports PDF (PyMuPDF), DOCX 
      (python-docx), and TXT formats.
      
      Used by:
      - API pipeline: POST /admin/knowledge-base/sync-jobs
      - Watcher pipeline: apps/api/api/ingestion/watcher.py (Story 6.1+)
      
      See also:
      - docs/architecture/addendum-enhanced-document-extraction.md
      - docs/architecture/ingestion-pipelines-comparison.md
      
      Examples:
          >>> extractor = DocumentExtractor()
          >>> result = extractor.extract(Path("document.pdf"))
          >>> print(result.keys())
          ['text', 'images', 'tables', 'metadata']
      """
      
      def extract(self, file_path: Path) -> Dict[str, Any]:
          """Extract text, images, tables from document.
          
          Args:
              file_path: Path to document (PDF, DOCX, or TXT)
          
          Returns:
              {
                  "text": str,                      # Full document text
                  "images": List[Dict[str, Any]],   # Image metadata
                  "tables": List[Dict[str, Any]],   # Table structures
                  "metadata": {
                      "file_type": str,             # pdf|docx|txt
                      "images_count": int,          # Total images
                      "tables_count": int,          # Total tables
                      ...                           # Format-specific
                  }
              }
          
          Raises:
              FileNotFoundError: File does not exist
              ValueError: Unsupported file type
              Exception: Extraction errors (corrupted file, etc.)
          """
  ```
  
  **File: `apps/api/api/knowledge_base/classifier.py`**
  ```python
  def classify_content_enhanced(
      text: str,
      extraction_metadata: Dict[str, Any] | None = None,
  ) -> EnhancedClassificationOutput:
      """Classify document content with domain + structure detection.
      
      Uses OpenAI GPT to classify documents along two dimensions:
      1. Domain: fisioterapia_clinica, anatomia, patologia, etc.
      2. Structure: TESTO_ACCADEMICO_DENSO, DOCUMENTO_TABELLARE, etc.
      
      Classification results are cached in Redis for performance.
      
      Args:
          text: Document text to classify
          extraction_metadata: Optional metadata from DocumentExtractor
              (images_count, tables_count) used for structure hints
      
      Returns:
          EnhancedClassificationOutput with:
              - domain: ContentDomain enum
              - structure_type: DocumentStructureCategory enum
              - confidence: float (0.0-1.0)
              - reasoning: str (LLM explanation)
              - detected_features: Dict[str, bool]
      
      Raises:
          Exception: OpenAI API errors (after retries), invalid LLM output
      
      See also:
          - docs/architecture/addendum-enhanced-document-extraction.md
          - Story 2.5 (AC2): Enhanced classification implementation
      
      Examples:
          >>> metadata = {"images_count": 5, "tables_count": 2}
          >>> result = classify_content_enhanced(text, metadata)
          >>> print(result.domain, result.confidence)
          ContentDomain.FISIOTERAPIA_CLINICA 0.92
      """
  ```
  
  **File: `apps/api/api/ingestion/chunk_router.py`**
  ```python
  class ChunkRouter:
      """Route documents to appropriate chunking strategy based on classification.
      
      Supports:
      - RecursiveCharacterStrategy: For dense academic text
      - TabularStructuralStrategy: For documents with tables/sections
      - Fallback: When classification is None or low confidence (<0.7)
      
      See also:
          - docs/architecture/addendum-chunking-strategy-benchmark.md
          - Story 2.3: Polymorphic chunking router
          - Story 6.1: Watcher integration
      """
      
      def route(self, content: str, classification: Optional[ClassificazioneOutput]) -> ChunkingResult:
          """Route content to optimal chunking strategy.
          
          Args:
              content: Document text to chunk
              classification: Optional classification output from classify_content_enhanced()
                  If None or confidence < 0.7, uses fallback strategy
          
          Returns:
              ChunkingResult with:
                  - chunks: List[str]
                  - strategy_name: str (e.g., "recursive_character_800_160")
                  - parameters: Dict[str, Any] (strategy config)
          
          Strategy Selection:
              - TESTO_ACCADEMICO_DENSO ‚Üí RecursiveCharacterStrategy
              - DOCUMENTO_TABELLARE ‚Üí TabularStructuralStrategy
              - PAPER_SCIENTIFICO_MISTO ‚Üí TabularStructuralStrategy
              - None / low confidence ‚Üí Fallback (RecursiveCharacter)
          """
  ```
  
  **File: `apps/api/api/ingestion/watcher.py`**
  ```python
  def scan_once(cfg: IngestionConfig, inventory: Dict[str, str]) -> List[Document]:
      """Scan directory for new/changed documents and process them.
      
      Pipeline (Post-Story 6.1):
      1. Detect file changes via SHA256 hash comparison
      2. Extract text, images, tables with DocumentExtractor (PyMuPDF/python-docx)
      3. Classify document with LLM (if feature flag enabled)
      4. Route to optimal chunking strategy based on classification
      5. Save chunks and metadata to temp storage
      
      Feature Flags (via Settings):
          - watcher_enable_classification: Enable/disable LLM classification
          - classification_timeout_seconds: Max time for classification call
      
      Args:
          cfg: Ingestion configuration (watch_dir, temp_dir)
          inventory: Dict[file_path, file_hash] for change detection
      
      Returns:
          List[Document] with status: "chunked" (success) or "error" (failure)
      
      See also:
          - docs/architecture/ingestion-pipelines-comparison.md
          - Story 6.1: Watcher enhancement with classification
      
      Notes:
          - Graceful degradation: Classification failure ‚Üí fallback chunking
          - Sequential processing: No concurrent file handling
          - Skips files with unchanged hash (inventory check)
      """
  ```

- [ ] Verificare che tutti i docstring siano compatibili con generatori di documentazione (Sphinx, pdoc)
- [ ] Run docstring linter: `poetry run ruff check --select D apps/api`

## Dev Notes

### Relevant Files to Update

**Documentation Files:**
- `docs/architecture/addendum-chunking-strategy-benchmark.md`
- `docs/architecture/addendum-langchain-loaders-splitters.md`
- `docs/architecture/index.md`
- `README.md` (if exists with features section)

**New Documentation Files to Create:**
- `docs/architecture/feature-roadmap.md`
- `docs/architecture/feature-status.md`

**Code Files (Docstrings):**
- `apps/api/api/knowledge_base/extractors.py`
- `apps/api/api/knowledge_base/classifier.py`
- `apps/api/api/ingestion/chunk_router.py`
- `apps/api/api/ingestion/watcher.py`

**Code Files (Comments):**
- Any file with `# Phase 2` comments (search with grep)

### Search Commands

```bash
# Find all "separators" references
grep -r "separators.*default" docs/

# Find all "Phase 2" comments
grep -r "Phase 2" apps/api/

# Find docstring coverage
poetry run interrogate apps/api/api/ --verbose
```

### Testing Strategy

**Documentation Validation:**
- [ ] All links are valid (no 404s)
- [ ] All code examples are syntactically correct
- [ ] Mermaid diagrams render correctly
- [ ] Markdown tables are well-formed

**Docstring Validation:**
- [ ] All public functions have docstrings
- [ ] Docstring format consistent (Google style)
- [ ] Parameter types match function signatures
- [ ] Examples are executable and correct

**Manual Review Checklist:**
1. [ ] Read updated benchmark doc ‚Üí clear pipeline scope
2. [ ] Read feature-roadmap.md ‚Üí clear MVP vs Phase 2
3. [ ] Read feature-status.md ‚Üí accurate current state
4. [ ] Check separator references ‚Üí all corrected
5. [ ] Check Phase 2 comments ‚Üí all have links

### No Code Changes Required

**Important:** This story is **documentation-only**. No functional code changes, only:
- Docstring updates (documentation embedded in code)
- Comment improvements (better readability)
- No logic changes, no new features, no bug fixes

### Testing

**Manual Testing:**
- [ ] Build documentation locally (if using Sphinx/MkDocs)
- [ ] Verify all internal links work
- [ ] Verify external links work
- [ ] Read through updated docs for clarity

**Automated Testing:**
- [ ] Docstring linter: `poetry run ruff check --select D`
- [ ] Markdown linter: `markdownlint docs/`
- [ ] Link checker: `markdown-link-check docs/**/*.md`

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-17 | 1.0 | Initial story creation - Documentation corrections & cleanup | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used

_To be filled by dev agent_

### Debug Log References

_To be filled by dev agent_

### Completion Notes List

_To be filled by dev agent_

### File List

_To be filled by dev agent_

## QA Results

_To be filled by QA agent_

