# Story 6.1: Pipeline Documentation & Watcher Enhancement

**Status:** Ready for Dev

## Story

**Come** sviluppatore del sistema,
**voglio** avere documentazione chiara sulle due pipeline di ingestion e una pipeline watcher potenziata con classificazione LLM,
**in modo da** garantire qualità uniforme dei chunk e comprensione completa dell'architettura.

## Context

Un'analisi approfondita ha rivelato che esistono **due pipeline di ingestion completamente separate** con capacità molto diverse:

### Pipeline A: Watcher (Automatica) - `apps/api/api/ingestion/watcher.py`
**Stato attuale:**
- ❌ Usa LangChain basic extraction (PyPDFLoader, Docx2txtLoader)
- ❌ NO classificazione LLM (passa sempre `classification=None`)
- ❌ NO PyMuPDF extraction avanzata
- ❌ NO metadata immagini/tabelle
- ✅ Chunking fallback fisso: `RecursiveCharacterStrategy(800, 160)`

**Commento esplicito nel codice (linea 47):**
```python
# Classificazione: per ora non presente nella pipeline end-to-end → None
router = ChunkRouter()
routing = router.route(content, classification=None)  # ← Sempre fallback!
```

### Pipeline B: API Sync-Jobs (Manuale) - `apps/api/api/routers/knowledge_base.py`
**Stato attuale:**
- ✅ Usa `DocumentExtractor` con PyMuPDF (immagini, tabelle, caption detection)
- ✅ Classificazione LLM enhanced (`classify_content_enhanced`)
- ✅ Chunking intelligente basato su classificazione
- ✅ Metadata completi (images_count, tables_count, domain, structure_type)
- ✅ Cache Redis per classificazioni

### Problema

**La documentazione descrive solo la Pipeline B**, creando false aspettative. Gli sviluppatori non sanno che la pipeline automatica (probabilmente la più usata) non ha le stesse capabilities.

**Impatto operativo:**
- Documenti processati automaticamente non beneficiano di chunking ottimale
- Classificazione ignorata → sempre `TabularStructuralStrategy` non viene mai usata
- Metadata immagini/tabelle mancanti per documenti watcher

## Acceptance Criteria

### AC1: Documentazione Pipeline Duale
- [ ] Creato documento `docs/architecture/ingestion-pipelines-comparison.md` che spiega:
  - Le due modalità (watcher automatica vs API manuale)
  - Use case per ciascuna
  - Differenze di capabilities
  - Trade-off (performance, qualità, costi)
- [ ] Tabella comparativa chiara: Features × Pipeline
- [ ] Diagrammi di flusso per entrambe le pipeline
- [ ] Link incrociati da altri documenti architetturali

### AC2: Integrazione DocumentExtractor in Watcher
- [ ] Watcher usa `DocumentExtractor` invece di `extract_text()` basic
- [ ] Extraction PyMuPDF attiva per PDF (immagini, tabelle, metadata)
- [ ] Extraction python-docx attiva per DOCX (tabelle strutturate)
- [ ] Metadata completi (`images_count`, `tables_count`) propagati

### AC3: Classificazione LLM in Watcher con Feature Flag
- [ ] Feature flag `WATCHER_ENABLE_CLASSIFICATION` in config con default esplicito: `true`
- [ ] Timeout configurabile `CLASSIFICATION_TIMEOUT_SECONDS` con default esplicito: `10` secondi
- [ ] Se flag=true: classificazione LLM chiamata prima di chunking
- [ ] Se flag=false: comportamento attuale (fallback diretto)
- [ ] Graceful degradation: se classificazione fallisce → fallback + log warning
- [ ] Governance costi: classificazione deve avvenire SOLO su documenti nuovi o modificati (non su re-scan di file invariati)
- [ ] Log strutturato: latenza classificazione, successo/fallimento, caching hit-rate

### AC4: Chunking Intelligente Attivo
- [ ] Router riceve classificazione (non più `None`)
- [ ] Soglia confidenza routing: `min_confidence = 0.7` (esplicita)
- [ ] Se `confidence < 0.7`: fallback a strategia default
- [ ] `TabularStructuralStrategy` (nome esatto: `tabular_structural`) usata per `DOCUMENTO_TABELLARE`
- [ ] `RecursiveCharacterStrategy` (nome esatto: `recursive_character_800_160`) usata per `TESTO_ACCADEMICO_DENSO`
- [ ] Strategia applicata registrata in `document.chunking_strategy` con nome completo
- [ ] Metriche log obbligatorie:
  - [ ] Latenza classificazione (p50, p95, p99)
  - [ ] Success/failure ratio classificazione
  - [ ] Fallback ratio (target: <15% in produzione)
  - [ ] Strategy distribution: recursive vs tabular vs fallback (%)
  - [ ] Cache hit-rate classificazione (target: ≥40% dopo warmup)

### AC5: Test Coverage Pipeline Watcher Enhanced
- [ ] Test unitari per `DocumentExtractor` integration
- [ ] Test classificazione con feature flag (on/off)
- [ ] **Test compatibilità legacy**: Con `WATCHER_ENABLE_CLASSIFICATION=false`, comportamento del watcher deve essere identico a versione pre-6.1 (validare con test comparativo)
- [ ] Test graceful degradation (classificazione fallisce)
- [ ] Test metadata propagation (images_count, tables_count)
- [ ] Test routing strategie (mocked classification)
- [ ] Test coverage watcher module >85%
- [ ] Test validazione metriche: verificare che tutti i log obbligatori di AC4 vengano emessi correttamente

### AC6: Aggiornamento Documentazione Architetturale
- [ ] `addendum-chunking-strategy-benchmark.md` aggiornato con nota:
  ```markdown
  ## Note Implementazione
  ⚠️ **IMPORTANTE:** I benchmark si riferiscono alla strategia applicata da entrambe 
  le pipeline dopo Story 6.1. Pre-6.1, solo pipeline API usava classificazione intelligente.
  ```
- [ ] Link a `ingestion-pipelines-comparison.md` da tutti i doc rilevanti
- [ ] Commento "per ora non presente" rimosso dal codice watcher

### AC7: Osservabilità e Monitoraggio (Promosso da QA)
- [ ] Sistema di metriche implementato per pipeline watcher con le seguenti dimensioni:
  - [ ] **Latenza classificazione**: p50, p95, p99 per chiamate LLM
  - [ ] **Success/Failure ratio**: % successo vs fallimento classificazione
  - [ ] **Fallback ratio**: % documenti che usano strategia fallback (target: <15%)
  - [ ] **Strategy distribution**: % documenti per strategia (recursive/tabular/fallback)
  - [ ] **Cache performance**: hit-rate Redis cache classificazioni (target: ≥40%)
- [ ] Log strutturato JSON per tutti gli eventi rilevanti:
  - [ ] Classificazione richiesta/successo/fallimento con timing
  - [ ] Routing strategia applicata con confidence
  - [ ] Fallback events con reason code
  - [ ] Cache hit/miss events
- [ ] Metriche esportate in formato compatibile con monitoring dashboard
- [ ] Alert configurabili per:
  - [ ] Fallback ratio > 20% (warning)
  - [ ] Classification failure rate > 10% (warning)
  - [ ] p95 latency > 5s (critical)
- [ ] Validazione staging SLO prima del deploy in produzione:
  - [ ] p50 latency < 1.5s per documento
  - [ ] p95 latency < 5s per documento
  - [ ] Fallback ratio < 15%
  - [ ] Cache hit-rate ≥ 40% dopo warmup

## Tasks / Subtasks

### Task 1: Creare Documentazione Pipeline Comparison (AC1)
- [ ] Creare `docs/architecture/ingestion-pipelines-comparison.md`
  - [ ] Sezione: Overview delle due modalità
  - [ ] Tabella comparativa features
  - [ ] Diagramma flusso Pipeline Watcher (Mermaid)
  - [ ] Diagramma flusso Pipeline API (Mermaid)
  - [ ] Sezione: Quando usare quale pipeline
  - [ ] Sezione: Trade-offs (performance, qualità, costi)
- [ ] Aggiungere link da `docs/architecture/index.md`
- [ ] Aggiungere link da `addendum-chunking-strategy-benchmark.md`
- [ ] Aggiungere link da `addendum-enhanced-document-extraction.md`

### Task 2: Integrare DocumentExtractor in Watcher (AC2)
- [ ] Modificare `apps/api/api/ingestion/watcher.py`:
  - [ ] Importare `DocumentExtractor` da `knowledge_base.extractors`
  - [ ] Sostituire `extract_text(full)` con `DocumentExtractor().extract(full)`
  - [ ] Estrarre `text` da `extraction_result["text"]`
  - [ ] Estrarre `metadata` da `extraction_result["metadata"]`
  - [ ] Propagare `metadata` al documento (`doc.metadata.update(extraction_metadata)`)
- [ ] Gestire eccezioni extraction (file corrotti, formati non supportati)
- [ ] Log dettagliato: file type, extraction duration, metadata counts

### Task 3: Aggiungere Feature Flag per Classificazione (AC3)
- [ ] Aggiungere variabili env in `.env` template:
  ```env
  # Watcher Configuration
  WATCHER_ENABLE_CLASSIFICATION=true
  CLASSIFICATION_TIMEOUT_SECONDS=10
  ```
- [ ] Aggiungere settings in `apps/api/api/config.py`:
  ```python
  watcher_enable_classification: bool = True
  classification_timeout_seconds: int = 10
  ```
- [ ] Modificare `watcher.py`:
  - [ ] Leggere `settings.watcher_enable_classification`
  - [ ] Se `true`: chiamare `classify_content_enhanced(content, metadata)`
  - [ ] Se `false`: usare `classification=None` (comportamento attuale)
  - [ ] Try-except con timeout e fallback graceful
  - [ ] Log: classification success/failure/skipped con timing

### Task 4: Implementare Chunking Intelligente (AC4)
- [ ] Modificare logica routing in `watcher.py`:
  ```python
  # Vecchio (sempre None):
  # routing = router.route(content, classification=None)
  
  # Nuovo (con classificazione):
  classification = None
  if settings.watcher_enable_classification:
      try:
          classification = classify_content_enhanced(content, metadata, timeout=settings.classification_timeout_seconds)
      except Exception as e:
          logger.warning({
              "event": "watcher_classification_failed",
              "file": str(full),
              "error": str(e)
          })
  
  routing = router.route(content, classification)  # ← Non più sempre None!
  doc.chunking_strategy = routing.strategy_name
  ```
- [ ] Aggiungere metriche log:
  - [ ] Strategy distribution (recursive vs tabular vs fallback)
  - [ ] Classification success rate
  - [ ] Average classification latency

### Task 5: Scrivere Test per Watcher Enhanced (AC5)
- [ ] Creare `apps/api/tests/test_watcher_enhanced.py`:
  - [ ] Test: DocumentExtractor integration (PDF, DOCX, TXT)
  - [ ] Test: Metadata extraction (images_count, tables_count)
  - [ ] Test: Feature flag ON - classificazione chiamata
  - [ ] Test: Feature flag OFF - classificazione skippata
  - [ ] Test: Classificazione fallisce - graceful fallback
  - [ ] Test: Routing strategies based on classification
    - [ ] Mock classification → `TESTO_ACCADEMICO_DENSO` → RecursiveStrategy
    - [ ] Mock classification → `DOCUMENTO_TABELLARE` → TabularStrategy
    - [ ] Classification=None → fallback strategy
  - [ ] Test: Timeout handling per classificazione
- [ ] Eseguire coverage: `poetry run pytest tests/test_watcher_enhanced.py --cov=api.ingestion.watcher`
- [ ] Target: >85% coverage watcher module

### Task 6: Aggiornare Documentazione Architetturale (AC6)
- [ ] Modificare `docs/architecture/addendum-chunking-strategy-benchmark.md`:
  - [ ] Aggiungere sezione "Note Implementazione" prima di "## Benchmark Retrieval"
  - [ ] Citare Story 6.1 e cambiamenti pipeline watcher
  - [ ] Chiarire che benchmark post-6.1 si applicano a entrambe pipeline
- [ ] Rimuovere commento "per ora non presente" da `watcher.py` (linea 47)
- [ ] Aggiornare docstring `watcher.scan_once()` con nuove capabilities
- [ ] Aggiornare `docs/architecture/sezione-6-componenti.md` se presente

### Task 7: Implementare Sistema Osservabilità (AC7)
- [ ] Creare modulo metriche `apps/api/api/ingestion/watcher_metrics.py`:
  - [ ] Classe `WatcherMetrics` per raccolta metriche
  - [ ] Metodi per tracking latency (p50, p95, p99)
  - [ ] Metodi per tracking success/failure classification
  - [ ] Metodi per tracking fallback ratio
  - [ ] Metodi per tracking strategy distribution
  - [ ] Metodi per tracking cache hit-rate
- [ ] Integrare metriche in `watcher.py`:
  - [ ] Instrumentare classificazione con timing
  - [ ] Registrare success/failure events
  - [ ] Registrare routing strategy applicata
  - [ ] Registrare cache hit/miss
  - [ ] Log strutturato JSON per tutti gli eventi
- [ ] Implementare export metriche:
  - [ ] Formato compatibile con Prometheus/Grafana
  - [ ] Endpoint `/metrics` FastAPI (se non esistente)
  - [ ] Documentare formato export in `docs/operations/monitoring.md`
- [ ] Configurare alert thresholds:
  - [ ] Fallback ratio > 20% → warning
  - [ ] Classification failure > 10% → warning
  - [ ] p95 latency > 5s → critical
  - [ ] Documentare configurazione alert in config
- [ ] Validazione staging SLO:
  - [ ] Script validazione: `scripts/validation/validate_watcher_slo.py`
  - [ ] Verifica p50 < 1.5s, p95 < 5s
  - [ ] Verifica fallback < 15%
  - [ ] Verifica cache hit-rate ≥ 40%
  - [ ] Report validazione in `reports/6.1/staging-slo-validation.md`

## Dev Notes

### Relevant Architecture

**Tech Stack (da `docs/architecture/sezione-3-tech-stack.md`):**
- **LangChain**: Document loaders, text splitters (già in uso)
- **PyMuPDF (fitz)**: PDF extraction con immagini/tabelle (già implementato in `DocumentExtractor`)
- **OpenAI**: GPT per classificazione LLM (già implementato in `classifier.py`)
- **Redis**: Classification cache (opzionale, già implementato)
- **FastAPI**: Backend framework con Pydantic settings
- **Pytest**: Testing framework

**Existing Components:**
1. **`DocumentExtractor`** (`apps/api/api/knowledge_base/extractors.py`):
   - Già implementato e funzionante
   - Supporta PDF (PyMuPDF), DOCX (python-docx), TXT
   - Estrae immagini, tabelle, metadata
   - Usato dalla pipeline API, non dalla watcher

2. **`classify_content_enhanced`** (`apps/api/api/knowledge_base/classifier.py`):
   - Già implementato e funzionante
   - Usa OpenAI GPT per classificazione
   - Supporta cache Redis
   - Restituisce `EnhancedClassificationOutput` con domain, structure_type, confidence

3. **`ChunkRouter`** (`apps/api/api/ingestion/chunk_router.py`):
   - Già implementato
   - Routing basato su `ClassificazioneOutput`
   - Supporta fallback se `classification=None` o `confidenza < 0.7`

4. **`ClassificationCache`** (`apps/api/api/knowledge_base/classification_cache.py`):
   - Redis-backed cache con graceful degradation
   - Singleton pattern con thread-safety
   - Metrics (hit rate, latency)

### Pipeline Watcher Current Flow

```python
# apps/api/api/ingestion/watcher.py - CURRENT (Simple)
def scan_once(cfg: IngestionConfig, inventory: Dict[str, str]):
    for file in files:
        # 1. Extract text (LangChain basic)
        content = extract_text(full)  # ← PyPDFLoader/Docx2txtLoader
        
        # 2. Chunking (always fallback)
        router = ChunkRouter()
        routing = router.route(content, classification=None)  # ← SEMPRE None!
        
        # 3. Save chunks
        save_chunks(file_hash, routing.chunks, cfg.temp_dir)
```

### Pipeline Watcher TARGET Flow (Post-6.1)

```python
# apps/api/api/ingestion/watcher.py - TARGET (Enhanced)
from ..knowledge_base.extractors import DocumentExtractor
from ..knowledge_base.classifier import classify_content_enhanced

def scan_once(cfg: IngestionConfig, inventory: Dict[str, str], settings: Settings):
    extractor = DocumentExtractor()
    
    for file in files:
        # 1. Extract with PyMuPDF/python-docx (Advanced)
        extraction_result = extractor.extract(full)  # ← PyMuPDF!
        content = extraction_result["text"]
        metadata = extraction_result["metadata"]  # images_count, tables_count
        
        # 2. Classify (optional with feature flag)
        classification = None
        if settings.watcher_enable_classification:
            try:
                classification = classify_content_enhanced(
                    content, 
                    metadata,
                    timeout=settings.classification_timeout_seconds
                )
            except Exception as e:
                logger.warning({"event": "classification_failed", "error": str(e)})
        
        # 3. Intelligent chunking (not always fallback!)
        router = ChunkRouter()
        routing = router.route(content, classification)  # ← Classification data!
        
        # 4. Save chunks with metadata
        doc.metadata.update(metadata)  # Propagate images_count, tables_count
        doc.chunking_strategy = routing.strategy_name
        save_chunks(file_hash, routing.chunks, cfg.temp_dir)
```

### Configuration Management

**Pydantic Settings Pattern** (da tech stack):
```python
# apps/api/api/config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # Existing settings...
    
    # New: Watcher Configuration
    watcher_enable_classification: bool = True
    classification_timeout_seconds: int = 10
    
    class Config:
        env_file = ".env"
        case_sensitive = False
```

### Testing Strategy

**Test Structure:**
```python
# apps/api/tests/test_watcher_enhanced.py
import pytest
from unittest.mock import Mock, patch
from api.ingestion.watcher import scan_once
from api.knowledge_base.extractors import DocumentExtractor
from api.knowledge_base.classifier import classify_content_enhanced

@pytest.fixture
def mock_settings():
    return Mock(
        watcher_enable_classification=True,
        classification_timeout_seconds=10
    )

def test_watcher_uses_document_extractor(mock_settings, tmp_path):
    """Verify watcher calls DocumentExtractor instead of basic extract_text."""
    # Setup test file
    test_pdf = tmp_path / "test.pdf"
    # ... create test PDF
    
    with patch('api.ingestion.watcher.DocumentExtractor') as mock_extractor:
        mock_extractor.return_value.extract.return_value = {
            "text": "test content",
            "metadata": {"images_count": 2, "tables_count": 1}
        }
        
        # Run watcher
        results = scan_once(cfg, {}, mock_settings)
        
        # Assertions
        mock_extractor.return_value.extract.assert_called_once()
        assert results[0].metadata["images_count"] == 2

def test_classification_feature_flag_enabled(mock_settings):
    """When flag=true, classification should be called."""
    with patch('api.ingestion.watcher.classify_content_enhanced') as mock_classify:
        mock_classify.return_value = Mock(
            structure_type="TESTO_ACCADEMICO_DENSO",
            confidence=0.85
        )
        
        results = scan_once(cfg, {}, mock_settings)
        
        mock_classify.assert_called_once()
        assert results[0].chunking_strategy == "recursive_character_800_160"

def test_classification_feature_flag_disabled():
    """When flag=false, classification should be skipped."""
    settings = Mock(watcher_enable_classification=False)
    
    with patch('api.ingestion.watcher.classify_content_enhanced') as mock_classify:
        results = scan_once(cfg, {}, settings)
        
        mock_classify.assert_not_called()
        # Should use fallback strategy
        assert "fallback" in results[0].chunking_strategy

def test_classification_timeout_graceful_fallback():
    """When classification times out, should fallback gracefully."""
    settings = Mock(
        watcher_enable_classification=True,
        classification_timeout_seconds=1
    )
    
    with patch('api.ingestion.watcher.classify_content_enhanced') as mock_classify:
        mock_classify.side_effect = TimeoutError("Classification timeout")
        
        results = scan_once(cfg, {}, settings)
        
        # Should not raise, should use fallback
        assert "fallback" in results[0].chunking_strategy
```

### File Structure Changes

**New Files:**
- `docs/architecture/ingestion-pipelines-comparison.md` (new documentation)
- `apps/api/tests/test_watcher_enhanced.py` (new test file)

**Modified Files:**
- `apps/api/api/ingestion/watcher.py` (integrate DocumentExtractor + classification)
- `apps/api/api/config.py` (add watcher settings)
- `.env` template (add watcher env vars)
- `docs/architecture/addendum-chunking-strategy-benchmark.md` (add implementation note)
- `docs/architecture/index.md` (add link to new comparison doc)

### Performance Considerations

**Classification Overhead:**
- OpenAI API call: ~500-1500ms per document (depends on size)
- Cache hit: ~5-10ms (Redis lookup)
- Timeout configurabile: default 10s

**Mitigation:**
- Redis cache: hit rate atteso ~40-60% dopo warmup
- Feature flag: disabilitabile se performance critica
- Batch processing: watcher processa file sequenzialmente (no concorrenza)

**Expected Impact:**
- First run (cold cache): +1-2s per document
- Subsequent runs (warm cache): +10-50ms per document
- Quality improvement: chunking ottimale per ~80% documenti (vs 0% attuale)

### Security Considerations

**Environment Variables:**
- `WATCHER_ENABLE_CLASSIFICATION`: boolean, no security risk
- `CLASSIFICATION_TIMEOUT_SECONDS`: integer, sanity check (1-60s)
- OpenAI API key: già configurato, nessun cambiamento

**Input Validation:**
- DocumentExtractor gestisce file corrotti gracefully
- Classification timeout previene hanging su documenti problematici
- Fallback garantisce processing anche se classificazione fallisce

### Rollback Plan

Se problemi post-deploy:
1. **Quick fix**: Disabilitare feature flag (`WATCHER_ENABLE_CLASSIFICATION=false`)
2. **Hotfix**: Rollback commit, redeploy versione precedente
3. **Debug**: Logs dettagliati identificheranno problemi specifici

Feature flag permette A/B testing e rollout graduale.

### Testing

**Manual Testing Checklist:**
1. [ ] Upload PDF con immagini → verifica metadata `images_count`
2. [ ] Upload DOCX con tabelle → verifica metadata `tables_count`
3. [ ] Verifica classificazione chiamata (check logs)
4. [ ] Verifica strategy routing (non sempre "fallback")
5. [ ] Disabilita feature flag → verifica comportamento originale
6. [ ] Simula timeout classificazione → verifica fallback graceful

## QA Results

### Review Date: 2025-10-17

### Reviewed By: Quinn (Test Architect)

### Gate Status

Gate: CONCERNS → qa.qaLocation/gates/6.1-pipeline-documentation-watcher-enhancement.yml

**Automated Tests:**
- Run: `poetry run pytest tests/test_watcher_enhanced.py -v --cov=api.ingestion.watcher`
- Target: >85% coverage
- All tests green before merge

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-17 | 1.0 | Initial story creation - Pipeline documentation & watcher enhancement | Scrum Master (Bob) |
| 2025-10-17 | 2.0 | PO Validation Updates: AC3 defaults espliciti (flag=true, timeout=10s), AC3 governance costi, AC4 soglia confidenza (0.7) e nomi strategie esatti, AC4 metriche obbligatorie, AC5 test compatibilità legacy, AC7 Osservabilità promossa. Status: Ready for Dev | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used

_To be filled by dev agent_

### Debug Log References

_To be filled by dev agent_

### Completion Notes List

_To be filled by dev agent_

### File List

_To be filled by dev agent_

## QA Results

Risk Profile created: docs/qa/assessments/6.1-risk-profile-20251017.md

Summary:
- Overall posture: Medium (High impact if unmanaged)
- Top risks: performance regression (LLM calls), cross-pipeline parity gaps, cost spikes, excessive fallbacks, metadata propagation, routing correctness, config drift, observability gaps

Conditions to proceed:
- Tests per AC5 pass with >85% coverage for watcher
- Metrics/alerts in place (classification latency, success/failure, fallback ratio, strategy distribution)
- Staging validation: p50 < 1.5s, p95 < 5s per doc; fallback < 15%; cache hit-rate ≥ 40%
- Documentation AC1/AC6 updated and linked

Test Design created: docs/qa/assessments/6.1-test-design-20251017.md

Coverage & Validation Plan:
- Unit + integration tests for extractor integration, classification flag on/off, timeout fallback, routing strategies, metadata propagation
- Watcher coverage target: >85% with `--cov=api.ingestion.watcher`
- Docs validation for AC1 and AC6 (files exist, key sections/links present)

Gate Decision: docs/qa/gates/6.1-pipeline-documentation-watcher-enhancement.yml

Decision: CONCERNS — proceed with conditions
- Require AC5 tests passing and >85% coverage on watcher
- Deploy observability (latency/success/failure, fallback ratio, strategy distribution)
- Meet staging SLOs (p50 < 1.5s, p95 < 5s; fallback < 15%; cache hit-rate ≥ 40%)
- Complete documentation updates and code comment clean-up per AC1/AC6
