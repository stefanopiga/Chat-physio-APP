# Traceability Matrix — Story 2.4.2: Error Handling Ingestion Pipeline

## Scope
- **Story**: 2.4.2 — Implementazione Gestione Errori Pipeline di Ingestione (rif. L16-L23:docs/stories/2.4.2-error-handling-ingestion-pipeline.md)
- **Epic**: Epic 2 — Core Knowledge Pipeline (rif. L8:docs/stories/2.4.2-error-handling-ingestion-pipeline.md)
- **Priorità**: P0 - Critical Blocker (rif. L9:docs/stories/2.4.2-error-handling-ingestion-pipeline.md)

## Matrice AC → Implementazione → Test → Configurazioni

### AC1 — Rilevazione `openai.AuthenticationError` con HTTP 500 e log
- **Definizione**: L130-L148
```130:148:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
Then l'endpoint DEVE restituire HTTP 500 ...
And nei log DEVE apparire "openai.AuthenticationError" ...
```
- **Implementazione**: L79-L92 (try/except su OpenAI), L218-L244 (_get_embeddings_model)
```79:92:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
except openai.AuthenticationError as e:
    logger.error(...)
    raise
```
- **Test/Evidenze**: L647-L666 (log worker con 401, retry)
```654:659:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
[INFO] Inizio indexing 1 chunks
[ERROR] ... AuthenticationError: Error code: 401
[INFO] Task retry: Retry in 1s: AuthenticationError(...)
```

### AC2 — Rilevazione `openai.APIConnectionError` con HTTP 500 e causa
- **Definizione**: L150-L156
- **Implementazione**: L84-L86, L226-L231 (logging causa `__cause__` + raise)
- **Test/Evidenze**: scenario di disconnessione previsto (L156)

### AC3 — Fallimento insert Supabase: lista vuota/exception → HTTP 500 con messaggio specifico
- **Definizione**: L158-L169
```158:169:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
Then l'endpoint DEVE restituire HTTP 500 ...
And nei log DEVE apparire ... "Error inserting: No rows added"
```
- **Implementazione**: L94-L124, L279-L326 (verifica `ids`, gestione messaggi Supabase)
```279:291:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
ids = vector_store.add_texts(...)
if not ids or len(ids) == 0:
    logger.error(...)
    raise ValueError(...)
```
- **Test/Evidenze**: previsione comportamento e messaggi (L313-L318)
### AC4 — Success path: `inserted > 0` e log di successo
- **Definizione**: L171-L185
```171:185:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
Then response DEVE contenere "inserted": N con N > 0
And nei log DEVE apparire "Inseriti N chunks con successo"
```
- **Implementazione**: L101-L103 (log successo + return), L298-L302 (log e return count)
```298:302:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
logger.info(
    f"Inseriti {len(ids)} chunks con successo",
    extra={"inserted_count": len(ids)}
)
return len(ids)
```
- **Test/Evidenze**: L750-L759 (response async 0, worker 1 inserito), L778-L785 (verifica DB)
```754:759:docs/stories/2.4.2-error-handling-ingestion-pipeline.md
[INFO] ... 200 OK embeddings
[INFO] ... 201 Created Supabase
[INFO] Inseriti 1 chunks con successo
[INFO] Task kb_indexing_task succeeded: {'inserted': 1}
```

## Configurazioni, Migrazioni e Dipendenze
- **Permessi e RLS**: GRANT e DISABLE RLS (L520-L541)
- **Trigger `document_id`**: popolazione automatica (L545-L563)
- **Variabili ambiente**: OpenAI e `service_role` Supabase (L574-L595)

## Collegamenti Artefatti
- **Codice**: `apps/api/api/knowledge_base/indexer.py` (rif. L457-L459)
- **Endpoint fix**: `apps/api/api/main.py` per `chunk_index` (rif. L459-L460, L684-L695)
- **Script test**: `test_story_242_manual.ps1` (rif. L462-L464)
- **Evidence log**: blocchi log riportati (rif. L654-L659; L754-L759)

## Stato Tracciabilità
- **AC**: 4/4 mappati con implementazione e evidenze
- **DB**: trigger attivo, permessi configurati, RLS disabilitato (rif. L545-L572)
- **Async behavior**: endpoint async by design, risultato via job (rif. L668-L672)
