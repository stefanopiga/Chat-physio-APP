# risk_summary (paste into gate file):
risk_summary:
  totals:
    critical: 1
    high: 3
    medium: 3
    low: 3
  highest:
    id: TECH-001
    score: 9
    title: 'Configurazione LLM centralizzata rompe servizi esistenti'
  recommendations:
    must_fix:
      - 'Aggiungere test integrazione DI Settings per chat e classifier'
      - 'Validazione robusta env vars OPENAI_* con fallback sicuri'
      - 'Feature flag/rollback rapido per refactoring LLM'
    monitor:
      - 'Alert su errori runtime ChatOpenAI init'
      - 'Dashboard costi per modello/feature (token, tasso richieste)'


# Risk Profile: Story 2.12

Date: 2025-10-16
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 10
- Critical Risks: 1
- High Risks: 3
- Risk Score: 53/100

## Critical Risks Requiring Immediate Attention

### 1. TECH-001: Configurazione LLM centralizzata rompe servizi esistenti
**Score: 9 (Critical)**
**Probability**: High - Refactoring to DI across multiple services often misses call sites and optional params.
**Impact**: High - Chat/classification endpoints fail at runtime; user-visible downtime.
**Mitigation**:
- Incremental refactor with feature flag and dark launch
- Contract tests for `_get_llm()` in chat/classifier
- Backward-compatible defaults and None-handling for temperatures
  **Testing Focus**: Integration tests verifying DI wiring and runtime init of ChatOpenAI with env overrides.

## Risk Distribution

### By Category
- Security: 1 risks (0 critical)
- Performance: 2 risks (0 critical)
- Data: 2 risks (0 critical)
- Business: 2 risks (0 critical)
- Operational: 3 risks (1 critical via TECH counted separately)

### By Component
- Frontend: 0 risks
- Backend: 8 risks
- Database: 1 risks
- Infrastructure: 1 risks

## Detailed Risk Register

| Risk ID  | Description                                                                 | Prob | Impact | Score | Priority |
|--------- |------------------------------------------------------------------------------|------|--------|-------|----------|
| TECH-001 | DI/settings refactor breaks chat/classifier initialization                   | High | High   | 9     | Critical |
| OPS-001  | Missing OPENAI_* envs in env/prod cause misconfig or boot failure            | High | Medium | 6     | High     |
| TECH-002 | Inconsistent default/None handling for temperatures                          | Medium| High  | 6     | High     |
| PERF-001 | Model/temperature change increases latency and costs                         | Medium| Medium| 4     | Medium   |
| DATA-001 | Classification behavior drifts due to temperature misconfig                  | Medium| Medium| 4     | Medium   |
| SEC-001  | Accidental logging of OPENAI_API_KEY or sensitive params                     | Low  | High   | 3     | Low      |
| OPS-002  | Tests not updated; CI misses regressions for DI wiring                       | Medium| Medium| 4     | Medium   |
| BUS-001  | Partial centralization; teams keep hardcoding leading to cost inconsistency  | Medium| Medium| 4     | Medium   |
| OPS-003  | Lack of runtime monitoring on model init and error rates                     | Low  | Medium | 2     | Low      |
| DATA-002 | Env parsing (floats) fails on locale/format causing silent fallbacks         | Low  | Medium | 2     | Low      |

## Risk-Based Testing Strategy

### Priority 1: Critical Risk Tests
- End-to-end boot tests for API ensuring ChatOpenAI and classifier instantiate with DI settings
- Contract tests asserting temperature None is not passed; classification uses 1.0
- Env override tests for OPENAI_MODEL, OPENAI_TEMPERATURE_CHAT, OPENAI_TEMPERATURE_CLASSIFICATION

### Priority 2: High Risk Tests
- Failure injection: unset/malformed envs; ensure safe defaults and clear errors
- Backward-compat tests to ensure existing unit tests remain green

### Priority 3: Medium/Low Risk Tests
- Load tests for chat/classification endpoints at nominal RPS
- Logging tests to ensure API key is never logged
- Parsing tests for float envs with whitespace/locale variants

## Risk Acceptance Criteria

### Must Fix Before Production
- All critical risks (score 9)
- High risks affecting availability/configuration

### Can Deploy with Mitigation
- Medium risks with compensating integration tests and monitoring
- Low risks with alerts in place

### Accepted Risks
- None proposed at this time; revisit after initial rollout.

## Monitoring Requirements
- Error rate and latency on chat/classification endpoints by model/temperature
- Alerts on initialization failures for ChatOpenAI and classifier
- Cost dashboards segmented by feature and model

## Risk Review Triggers
- Changes to DI pattern or settings schema
- New model adoption or temperature policy changes
- Significant cost/latency deviations after rollout

```text
Risk profile: docs/qa/assessments/2.12-risk-20251016.md
```
