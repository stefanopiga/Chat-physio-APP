# Risk Profile: Story 2.5 - Intelligent Document Preprocessing & Pipeline Completion

**Date:** 2025-10-07  
**Reviewer:** Quinn (Test Architect)  
**Story ID:** 2.5  
**Story Title:** Intelligent Document Preprocessing & Pipeline Completion

## Executive Summary

- **Total Risks Identified:** 14
- **Critical Risks (Score 9):** 2
- **High Risks (Score 6):** 4
- **Medium Risks (Score 4):** 5
- **Low Risks (Score 2-3):** 3
- **Overall Risk Score:** 37/100 (High Risk - Significant Attention Required)

**Key Concerns:**
1. Chunks creati ma non embedati (produzione issue documentato)
2. Celery worker operational complexity
3. OpenAI API rate limiting su batch embedding
4. Pipeline monitoring gaps critici

## Critical Risks Requiring Immediate Attention

### 1. DATA-001: Embedding Failure - Chunks Created Without Vectors

**Score: 9 (Critical)**  
**Category:** Data Integrity  
**Probability:** High (3) - Already occurring in production (121 chunks non embedati documentati)  
**Impact:** High (3) - Semantic search completamente non funzionante, pipeline inutilizzabile

**Description:**  
Issue attivo in produzione: chunks inseriti in `document_chunks` table con `embedding = NULL`. Semantic search fallisce completamente. Root cause: Celery worker non running o OpenAI API call failures non gestiti.

**Affected Components:**
- `/apps/api/api/knowledge_base/indexer.py` - batch embedding logic
- `/apps/api/api/celery_app.py` - async task processing
- `document_chunks` table - vector storage

**Mitigation Strategy (Preventive + Detective):**

**Immediate Actions:**
1. Implementare `_embed_texts_with_retry()` con `tenacity` library
   - Retry logic per `RateLimitError`, `APIConnectionError`
   - Exponential backoff: 2s → 60s max
   - Max 5 retry attempts
2. Aggiungere pre-flight check OpenAI API health prima batch embedding
3. Logging dettagliato con structured JSON per ogni embedding batch
4. Implementare DB constraint validation: reject chunks senza embedding (dopo grace period)

**Testing Requirements:**
- Unit test: mock OpenAI failures (RateLimitError, Timeout, AuthError)
- Integration test: end-to-end pipeline con OpenAI API real
- Chaos test: kill Celery worker mid-embedding, verify retry/recovery
- Monitoring test: verify logs contain timing metrics + error details

**Residual Risk:** Medium - Zero-day OpenAI API outages possibili, mitigati da retry logic

**Owner:** Backend Dev + DevOps  
**Timeline:** Sprint Priority 1 - Must fix before any new ingestion

---

### 2. OPS-001: Celery Worker Operational Instability

**Score: 9 (Critical)**  
**Category:** Operational  
**Probability:** High (3) - Documentato: worker setup mancante/misconfigured  
**Impact:** High (3) - Pipeline completamente bloccata senza async processing

**Description:**  
Celery worker non presente in `docker-compose.yml` attuale o misconfigured. Senza worker running, tutti i task asincroni (embedding, chunking pesanti) rimangono in stato PENDING indefinitamente.

**Affected Components:**
- `/docker-compose.yml` - service definitions
- `/apps/api/api/celery_app.py` - Celery configuration
- Redis broker - message queue

**Mitigation Strategy (Preventive):**

**Immediate Actions:**
1. Aggiungere `celery-worker` service in `docker-compose.yml`
2. Aggiungere `redis` service per broker/backend
3. Implementare health check endpoint: `/api/v1/health/celery`
4. Configurare auto-restart policy per worker container
5. Documentare troubleshooting guide: "Celery Worker Not Running"

**Testing Requirements:**
- Integration test: verify Celery worker accepts tasks
- Resilience test: restart worker, verify task resume
- Health check test: `/health/celery` returns 200 quando worker up
- Documentation test: follow troubleshooting guide end-to-end

**Residual Risk:** Low - Container orchestration mitiga instability

**Owner:** DevOps + Backend Dev  
**Timeline:** Sprint Priority 1 - Prerequisite per pipeline operativa

---

## High Risks

### 3. PERF-001: OpenAI API Rate Limiting on Batch Embedding

**Score: 6 (High)**  
**Category:** Performance  
**Probability:** Medium (2) - Dipende da piano OpenAI e load concorrente  
**Impact:** High (3) - Pipeline timeout/fallimento per documenti grandi

**Description:**  
Batch embedding di 100+ chunks può eccedere rate limit OpenAI (es. 3000 TPM su tier free, 60 RPM). Fallimento pipeline con retry exhaustion.

**Affected Components:**
- `indexer.py` - `_embed_texts_with_retry()`
- OpenAI API - `text-embedding-ada-002` endpoint

**Mitigation:**
1. Implementare adaptive batch sizing: start 100, reduce a 50/25 se rate limit
2. Aggiungere exponential backoff (già pianificato con tenacity)
3. Configurare OpenAI API tier check: log current limits
4. Considerare embedding caching (Story 4.3 future)

**Testing:**
- Load test: 1000 chunks simultaneous ingestion
- Rate limit simulation: mock 429 responses, verify backoff
- Timing benchmark: measure embedding_ms per 100 chunks

**Residual Risk:** Medium - Rate limits external, non completamente controllabili

---

### 4. TECH-001: PyMuPDF Integration Complexity

**Score: 6 (High)**  
**Category:** Technical  
**Probability:** High (3) - Nuova dependency, extraction logic complessa  
**Impact:** Medium (2) - Extraction errors, immagini/tabelle perse

**Description:**  
PyMuPDF (fitz) è nuova dependency con API complessa. Estrazione immagini richiede spatial analysis per caption detection. Risk: bugs in extraction logic, memory leaks su PDF grandi.

**Affected Components:**
- `/apps/api/api/knowledge_base/extractors.py` - `_extract_pdf()`
- PyMuPDF library

**Mitigation:**
1. Unit test estensivi: sample PDFs con immagini/tabelle
2. Memory profiling: test con PDF 100+ pagine
3. Fallback a pypdf per text-only se PyMuPDF fails
4. Logging extraction metrics: images_count, tables_count, pages

**Testing:**
- Unit test: PDF con immagini embedded, verifica metadata extraction
- Edge case test: PDF corrotto, PDF protetto da password
- Memory test: 500 page PDF, monitor memory usage
- Comparison test: PyMuPDF vs pypdf output quality

**Residual Risk:** Low - Fallback mechanism mitiga failures

---

### 5. TECH-002: Pipeline Integration Timing Bottlenecks

**Score: 6 (High)**  
**Category:** Technical/Performance  
**Probability:** Medium (2) - 7 step pipeline con dipendenze sequenziali  
**Impact:** High (3) - Target 60s totale facilmente superabile

**Description:**  
Pipeline 7-step sequenziale: extraction → classification → chunking → persistence → embedding → indexing → status update. Ogni step aggiunge latency. Target 60s per documento medio a rischio.

**Affected Components:**
- `/apps/api/api/main.py` - `start_sync_job_enhanced()`
- Tutti moduli pipeline

**Mitigation:**
1. Implementare timing metrics per ogni step (già pianificato)
2. Identificare step parallelizzabili (classification + chunking parzialmente)
3. Aggiungere timeout configuration per ogni step
4. Implementare partial failure recovery: salvare stato intermedio

**Testing:**
- Performance benchmark: documento 50 pagine, misurare total_pipeline_ms
- Bottleneck analysis: identificare step > 10s
- Timeout test: simulate slow OpenAI API, verify graceful degradation

**Residual Risk:** Medium - External API latency non controllabile

---

### 6. DATA-002: Enhanced Classification Domain Accuracy

**Score: 6 (High)**  
**Category:** Data Quality  
**Probability:** Medium (2) - LLM classification non deterministica  
**Impact:** High (3) - Wrong chunking strategy → poor RAG quality

**Description:**  
Enhanced classification introduce 8 nuovi domini fisioterapici. LLM può misclassificare contenuto ambiguo (es. anatomia vs patologia). Wrong domain → wrong chunking strategy → semantic search degradato.

**Affected Components:**
- `/apps/api/api/knowledge_base/classifier.py` - `EnhancedClassificationOutput`
- LLM classification prompt

**Mitigation:**
1. Implementare confidence threshold: reject classification se < 0.7
2. Aggiungere validation: check classification contro keyword heuristics
3. Logging classification con reasoning per audit
4. Allow manual re-classification via admin UI (future)

**Testing:**
- Classification accuracy test: 50 sample docs, measure precision/recall
- Ambiguous content test: documento misto anatomia+patologia
- Confidence calibration: verify confidence correlates con accuracy
- Edge case: documento non-fisioterapico (tecnico generico)

**Residual Risk:** Medium - LLM intrinsically non-deterministic

---

## Medium Risks

### 7. SEC-001: OpenAI API Key Exposure in Logs

**Score: 4 (Medium)**  
**Category:** Security  
**Probability:** Medium (2) - Logging dettagliato pianificato, facile leak  
**Impact:** Medium (2) - API key compromise, costi non autorizzati

**Description:**  
Pipeline logging estensivo può accidentalmente loggare OpenAI API key in error messages o debug output.

**Mitigation:**
1. Implementare log sanitization: mask API keys in logs
2. Use environment variable indirection, mai log raw env vars
3. Configure log aggregation: prevent local disk log access
4. Rotate API keys periodicamente

**Testing:**
- Security test: grep logs per pattern API key
- Error simulation: force OpenAI auth error, verify no key in logs

**Residual Risk:** Low - Standard security practice

---

### 8. TECH-003: DOCX Image Extraction Incomplete

**Score: 4 (Medium)**  
**Category:** Technical  
**Probability:** Medium (2) - python-docx image extraction limitata  
**Impact:** Medium (2) - Metadata immagini perso, context parziale

**Description:**  
python-docx image extraction via relationships non include alt text/caption automaticamente. Informazioni contestuali perse.

**Mitigation:**
1. Implementare alt text extraction via `qn()` namespace queries
2. Fallback: proximity text analysis per caption detection
3. Log warning quando images senza caption
4. Phase 2: GPT-4 Vision per image description (out of scope)

**Testing:**
- Unit test: DOCX con immagini + alt text, verify extraction
- Edge case: immagini inline vs floating

**Residual Risk:** Medium - Caption detection non sempre reliable

---

### 9. OPS-002: Redis Broker Availability

**Score: 4 (Medium)**  
**Category:** Operational  
**Probability:** Low (1) - Redis highly reliable  
**Impact:** High (3) - Celery completamente down, no async processing

**Description:**  
Redis single point of failure per Celery broker/backend. Redis down → all tasks blocked.

**Mitigation:**
1. Configure Redis persistence (AOF + RDB)
2. Health check Redis in startup script
3. Implement graceful degradation: fallback a sync processing se Redis down (future)
4. Monitor Redis memory usage

**Testing:**
- Resilience test: stop Redis mid-task, verify error handling
- Recovery test: restart Redis, verify task queue recovery

**Residual Risk:** Low - Redis intrinsically stable

---

### 10. PERF-002: Large Document Memory Consumption

**Score: 4 (Medium)**  
**Category:** Performance  
**Probability:** Medium (2) - Documenti 100+ pagine comuni in fisioterapia  
**Impact:** Medium (2) - API container OOM crash

**Description:**  
PyMuPDF carica intero PDF in memoria. Documento 200 pagine con immagini può eccedere container memory limit.

**Mitigation:**
1. Implement streaming extraction: process page-by-page
2. Configure container memory limit + monitoring
3. Implement file size validation: reject files > 50MB
4. Log memory usage metrics in extraction phase

**Testing:**
- Load test: 200 page PDF, monitor memory usage
- Stress test: 5 simultaneous large document uploads

**Residual Risk:** Low - Size validation prevents extreme cases

---

### 11. DATA-003: Table Extraction Structure Loss

**Score: 4 (Medium)**  
**Category:** Data Quality  
**Probability:** Medium (2) - PDF table extraction notoriously complex  
**Impact:** Medium (2) - Informazioni strutturali perse

**Description:**  
Table extraction da PDF senza pdfplumber (Phase 2 optional) è limitata. Header/row relationships possono essere persi.

**Mitigation:**
1. Implement basic table detection con PyMuPDF
2. Log warning quando tables detected
3. Phase 2: integrate pdfplumber per advanced table parsing
4. Store raw table text come fallback

**Testing:**
- Unit test: PDF con tabelle complesse
- Comparison test: PyMuPDF vs pdfplumber output quality

**Residual Risk:** Medium - Complex tables require advanced parsing

---

### 12. OPS-003: Pipeline Monitoring Gaps

**Score: 4 (Medium)**  
**Category:** Operational  
**Probability:** Medium (2) - Monitoring non ancora implementato  
**Impact:** Medium (2) - Troubleshooting difficile, MTTR elevato

**Description:**  
Pipeline timing metrics pianificati ma dashboard/alerting mancanti. Difficult troubleshoot production issues.

**Mitigation:**
1. Implement structured logging JSON format
2. Create troubleshooting guide (già pianificato)
3. Phase 2: integrate monitoring dashboard (Grafana/Prometheus)
4. Alert su embedding failures, pipeline timeout

**Testing:**
- Documentation test: follow troubleshooting guide
- Log parsing test: verify structured JSON format

**Residual Risk:** Low - Troubleshooting guide mitiga partially

---

## Low Risks

### 13. TECH-004: File Type Detection Magic Bytes

**Score: 3 (Low)**  
**Category:** Technical  
**Probability:** Low (1) - File extension generalmente reliable  
**Impact:** High (3) - Wrong extractor → extraction failure

**Description:**  
File type detection basata solo su extension (`.pdf`, `.docx`). Files con extension rinominata causano extraction errors.

**Mitigation:**
1. Implement magic bytes verification (python-magic)
2. Fallback a extension se magic bytes ambigui
3. Log warning quando mismatch detected

**Testing:**
- Unit test: PDF rinominato `.txt`, verify detection
- Edge case: file senza extension

**Residual Risk:** Very Low - Rare scenario

---

### 14. BUS-001: Classification Latency Impact on UX

**Score: 3 (Low)**  
**Category:** Business/UX  
**Probability:** Low (1) - Classification < 3s target  
**Impact:** High (3) - Admin UX degraded se > 10s

**Description:**  
LLM classification call aggiunge 2-5s latency. Admin user experience degrada se upload feedback lento.

**Mitigation:**
1. Implement async job status polling UI
2. Show progress indicator: "Analyzing document..."
3. Implement classification caching per duplicate docs (future)

**Testing:**
- UX test: admin upload flow, measure perceived latency
- Benchmark: classification latency 10 documenti

**Residual Risk:** Very Low - Async processing mitiga UX impact

---

### 15. SEC-002: File Path Injection in Extraction

**Score: 2 (Low)**  
**Category:** Security  
**Probability:** Low (1) - Admin-only endpoint, authenticated  
**Impact:** Medium (2) - Directory traversal, file system access

**Description:**  
`file_path` parameter in extraction potenzialmente vulnerable a path traversal (`../../etc/passwd`). Mitigato da admin-only access.

**Mitigation:**
1. Implement path validation: reject `..` sequences
2. Whitelist allowed directories (knowledge base path only)
3. Sanitize file paths via `Path.resolve()`

**Testing:**
- Security test: attempt path traversal injection
- Authorization test: verify admin-only enforcement

**Residual Risk:** Very Low - Admin trust boundary

---

## Risk Matrix - Complete Inventory

| Risk ID  | Description                                | Category    | Probability | Impact     | Score | Priority |
|----------|--------------------------------------------|-------------|-------------|------------|-------|----------|
| DATA-001 | Embedding failure chunks senza vectors     | Data        | High (3)    | High (3)   | 9     | Critical |
| OPS-001  | Celery worker operational instability      | Operational | High (3)    | High (3)   | 9     | Critical |
| PERF-001 | OpenAI API rate limiting batch embedding   | Performance | Medium (2)  | High (3)   | 6     | High     |
| TECH-001 | PyMuPDF integration complexity             | Technical   | High (3)    | Medium (2) | 6     | High     |
| TECH-002 | Pipeline integration timing bottlenecks    | Technical   | Medium (2)  | High (3)   | 6     | High     |
| DATA-002 | Enhanced classification domain accuracy    | Data        | Medium (2)  | High (3)   | 6     | High     |
| SEC-001  | OpenAI API key exposure in logs            | Security    | Medium (2)  | Medium (2) | 4     | Medium   |
| TECH-003 | DOCX image extraction incomplete           | Technical   | Medium (2)  | Medium (2) | 4     | Medium   |
| OPS-002  | Redis broker availability                  | Operational | Low (1)     | High (3)   | 4     | Medium   |
| PERF-002 | Large document memory consumption          | Performance | Medium (2)  | Medium (2) | 4     | Medium   |
| DATA-003 | Table extraction structure loss            | Data        | Medium (2)  | Medium (2) | 4     | Medium   |
| OPS-003  | Pipeline monitoring gaps                   | Operational | Medium (2)  | Medium (2) | 4     | Medium   |
| TECH-004 | File type detection magic bytes            | Technical   | Low (1)     | High (3)   | 3     | Low      |
| BUS-001  | Classification latency UX impact           | Business    | Low (1)     | High (3)   | 3     | Low      |
| SEC-002  | File path injection in extraction          | Security    | Low (1)     | Medium (2) | 2     | Low      |

---

## Risk Distribution Analysis

### By Category

| Category    | Total | Critical | High | Medium | Low |
|-------------|-------|----------|------|--------|-----|
| Data        | 3     | 1        | 1    | 1      | 0   |
| Operational | 3     | 1        | 0    | 2      | 0   |
| Technical   | 4     | 0        | 2    | 1      | 1   |
| Performance | 2     | 0        | 1    | 1      | 0   |
| Security    | 2     | 0        | 0    | 1      | 1   |
| Business    | 1     | 0        | 0    | 0      | 1   |

**Critical Concentration:** Data integrity + Operational stability (Celery/embedding pipeline)

### By Component

| Component                 | Risks | Highest Score |
|---------------------------|-------|---------------|
| Embedding/Indexing        | 3     | 9 (Critical)  |
| Celery Worker             | 2     | 9 (Critical)  |
| Document Extraction       | 3     | 6 (High)      |
| Classification            | 1     | 6 (High)      |
| Pipeline Orchestration    | 2     | 6 (High)      |
| Security/Logging          | 2     | 4 (Medium)    |
| Infrastructure (Redis)    | 1     | 4 (Medium)    |

---

## Risk-Based Testing Strategy

### Priority 1: Critical Risk Tests (Must Pass)

**DATA-001 - Embedding Failure:**
- **Test Case 1.1:** Upload document → verify ALL chunks have non-NULL embeddings
  - Given: 50-page DOCX documento fisioterapico
  - When: Ingestion completes successfully (200 OK)
  - Then: Query `SELECT COUNT(*) FROM document_chunks WHERE embedding IS NULL AND document_id = ?` returns 0
- **Test Case 1.2:** Simulate OpenAI RateLimitError during embedding
  - Given: Mock OpenAI API return 429 status
  - When: Batch embedding executes
  - Then: Retry logic triggers, exponential backoff applied, eventual success after max 5 retries
- **Test Case 1.3:** Simulate OpenAI APIConnectionError
  - Given: Mock network failure during embedding
  - When: `_embed_texts_with_retry()` invoked
  - Then: Tenacity retry mechanism catches exception, retries with backoff, logs error details
- **Test Case 1.4:** End-to-end pipeline validation
  - Given: Fresh database, test document "lombalgia-acuta.docx"
  - When: Execute full pipeline ingestion
  - Then: Semantic search query "trattamento lombalgia" returns relevant chunks with scores > 0.7

**OPS-001 - Celery Worker Stability:**
- **Test Case 2.1:** Verify Celery worker running in Docker Compose
  - Given: `docker-compose up -d`
  - When: Check worker logs `docker logs fisiorag-celery-worker-1`
  - Then: Logs contain "celery@hostname ready"
- **Test Case 2.2:** Health check endpoint validation
  - Given: Celery worker running
  - When: GET `/api/v1/health/celery`
  - Then: Response 200 with `{"status": "healthy", "worker_count": 1}`
- **Test Case 2.3:** Task resilience - worker restart mid-task
  - Given: Ingestion task in progress (embedding phase)
  - When: `docker restart fisiorag-celery-worker-1`
  - Then: Task resumes from checkpoint OR retries from beginning, eventual completion
- **Test Case 2.4:** Redis broker connectivity
  - Given: Redis container running
  - When: Execute `docker exec -it fisiorag-redis-1 redis-cli PING`
  - Then: Response "PONG"

**Required Test Types:**
- **Unit Tests:** `test_robust_indexing.py` - retry logic, timing metrics
- **Integration Tests:** `test_pipeline_e2e.py` - full ingestion flow
- **Chaos Tests:** Celery worker kill/restart, Redis stop/start
- **Monitoring Tests:** Log output validation, structured JSON format

**Acceptance Criteria:** Zero critical risks unmitigated before production deployment

---

### Priority 2: High Risk Tests (Must Address)

**PERF-001 - OpenAI Rate Limiting:**
- Load test: 1000 chunks simultaneous embedding
- Backoff test: Mock 429 responses, measure retry delays
- Benchmark: Embedding latency < 30s per 100 chunks

**TECH-001 - PyMuPDF Extraction:**
- Unit tests: Sample PDFs with images/tables, verify metadata
- Memory test: 500-page PDF, monitor RAM usage < 2GB
- Edge cases: Corrupted PDF, password-protected PDF

**TECH-002 - Pipeline Timing:**
- Performance benchmark: 50-page document < 60s total
- Bottleneck analysis: Identify steps > 10s
- Timeout test: Verify graceful degradation

**DATA-002 - Classification Accuracy:**
- Accuracy test: 50 sample docs, measure precision/recall > 80%
- Confidence calibration: Reject classifications < 0.7 confidence
- Ambiguous content: Mixed domain documents

**Required Test Types:**
- **Performance Tests:** Load testing, benchmarking, profiling
- **Functional Tests:** Extraction accuracy, classification validation
- **Edge Case Tests:** Large files, corrupted files, ambiguous content

---

### Priority 3: Medium/Low Risk Tests (Standard Coverage)

**Medium Risks (SEC-001, TECH-003, OPS-002, PERF-002, DATA-003, OPS-003):**
- Security: Log sanitization test, path injection test
- Extraction: DOCX image alt text, table structure validation
- Infrastructure: Redis persistence, memory limits
- Monitoring: Troubleshooting guide validation

**Low Risks (TECH-004, BUS-001, SEC-002):**
- File type detection edge cases
- UX latency measurement
- Path traversal security test

**Test Coverage Target:** >= 85% code coverage, 100% AC coverage

---

## Risk Acceptance Criteria

### Must Fix Before Production (Blocking)

**Critical Risks - Score 9:**
1. **DATA-001:** Implement retry logic, verify 100% chunks embedati
2. **OPS-001:** Celery worker operational in Docker Compose, health check passing

**High Risks - Security/Data Integrity:**
3. **DATA-002:** Classification confidence threshold >= 0.7, validation logic implemented

### Can Deploy with Mitigation (Conditional)

**High Risks - Performance/Technical:**
- **PERF-001:** Rate limiting - Accept if retry logic + backoff implemented, monitoring in place
- **TECH-001:** PyMuPDF - Accept if fallback to pypdf exists, memory limits configured
- **TECH-002:** Pipeline timing - Accept if timing metrics logged, bottlenecks identified

**Medium Risks:**
- All medium risks deployable with logging, monitoring, troubleshooting docs

### Accepted Risks (Documented)

**Low Risks:**
- **TECH-004:** File type detection - Accept, rare scenario, mitigation documented
- **BUS-001:** Classification latency - Accept, async processing sufficient UX
- **SEC-002:** Path injection - Accept, admin-only trust boundary

**Sign-off Required:** Product Owner (admin UX impact), Tech Lead (technical debt acceptance)

---

## Monitoring Requirements Post-Deployment

### Performance Metrics (PERF Risks)

**Dashboards:**
- Pipeline timing: `extraction_ms`, `classification_ms`, `embedding_ms`, `total_pipeline_ms`
- OpenAI API latency: request duration, rate limit hit count
- Celery task metrics: queue depth, task duration, failure rate

**Alerts:**
- Embedding latency > 60s per 100 chunks → WARNING
- Pipeline total time > 120s → WARNING
- OpenAI rate limit hit → INFO (expected with retry)

### Operational Metrics (OPS Risks)

**Dashboards:**
- Celery worker status: alive/dead, task count, error rate
- Redis metrics: memory usage, connection count, persistence lag
- Container health: CPU, memory, disk usage

**Alerts:**
- Celery worker down > 5 minutes → CRITICAL
- Redis memory > 80% → WARNING
- Container OOM → CRITICAL

### Data Quality Metrics (DATA Risks)

**Dashboards:**
- Chunks embedding status: percentage with NULL embeddings
- Classification confidence distribution: < 0.7 count
- Extraction errors: failed documents, error types

**Alerts:**
- Chunks with NULL embedding > 5% → CRITICAL
- Classification confidence < 0.7 > 20% of docs → WARNING
- Extraction failure rate > 10% → WARNING

### Security Metrics (SEC Risks)

**Dashboards:**
- API key exposure attempts: log grep for key patterns
- File path validation rejections: path traversal attempts

**Alerts:**
- API key detected in logs → CRITICAL
- Path traversal attempt → WARNING

**Monitoring Stack:** Structured JSON logs → Log aggregation (future: ELK/Grafana)

---

## Risk Review Triggers

Update risk profile when:

1. **Architecture Changes:**
   - New extraction libraries integrated (pdfplumber Phase 2)
   - Embedding model changed (ada-002 → alternative)
   - Celery replaced with alternative async framework

2. **Integration Changes:**
   - OpenAI API tier upgraded (rate limit changes)
   - Supabase vector storage migration
   - New file types supported (RTF, HTML)

3. **Security Incidents:**
   - OpenAI API key leaked
   - Unauthorized file access detected
   - Data breach in vector storage

4. **Performance Issues:**
   - Pipeline timing exceeds 120s consistently
   - OOM crashes in production
   - Rate limiting blocking ingestion

5. **Regulatory Requirements:**
   - GDPR data retention policy changes
   - Medical data compliance requirements
   - Audit logging mandates

**Review Cadence:** Post-deployment +1 week, then monthly, or triggered by above events

---

## Recommendations Summary

### Development Focus (In Priority Order)

1. **Immediate (Sprint Priority 1):**
   - Implement `_embed_texts_with_retry()` with tenacity (DATA-001)
   - Add Celery worker + Redis to docker-compose.yml (OPS-001)
   - Create troubleshooting guide `/docs/troubleshooting/pipeline-ingestion.md`
   - Implement timing metrics in pipeline (all steps)

2. **Sprint Priority 2:**
   - PyMuPDF extraction with memory limits (TECH-001)
   - Enhanced classification with confidence threshold (DATA-002)
   - OpenAI rate limit adaptive batching (PERF-001)
   - Log sanitization for API keys (SEC-001)

3. **Technical Debt (Phase 2):**
   - pdfplumber integration for table extraction (DATA-003)
   - Monitoring dashboard implementation (OPS-003)
   - Embedding caching (PERF optimization)
   - GPT-4 Vision for image caption extraction

### Testing Priority

**Must Have Before Merge:**
- Critical risk tests (Priority 1): 100% coverage
- High risk tests (Priority 2): >= 80% coverage
- E2E pipeline validation: document → search → chat

**Nice to Have:**
- Medium risk tests: >= 60% coverage
- Chaos engineering: advanced resilience tests
- Performance benchmarking: full load testing

### Deployment Strategy

**Recommended Approach:** Phased Rollout
1. **Phase 1 (Week 1):** Deploy with critical risk mitigations only
   - Celery worker operational
   - Retry logic implemented
   - Troubleshooting guide published
2. **Phase 2 (Week 2):** Monitor production, add high risk mitigations
   - PyMuPDF extraction
   - Enhanced classification
   - Rate limit handling
3. **Phase 3 (Week 3+):** Iterative improvement based on metrics
   - Performance optimization
   - Advanced monitoring
   - Table extraction enhancement

**Rollback Plan:** Revert to Story 2.4 state (basic pypdf extraction, no enhanced classification)

---

## Quality Gate Recommendation

**Gate Decision:** **CONCERNS** (Conditional Pass)

**Rationale:**
- 2 Critical risks (score 9) identified, mitigations defined but NOT YET IMPLEMENTED
- 4 High risks (score 6) require attention before production
- Overall risk score 37/100 indicates significant complexity

**Conditions for PASS:**
1. DATA-001 mitigation implemented: retry logic + verification test passing
2. OPS-001 mitigation implemented: Celery worker operational in docker-compose
3. Troubleshooting guide created and validated
4. E2E test passing: document ingestion → semantic search → chat response

**Timeline:** 2-3 sprint days for critical risk mitigation + testing

**Final Recommendation:** Story implementable with disciplined risk management. Critical risks have clear mitigation paths. Monitor closely post-deployment.

---

## Appendix: Risk Scoring Calculation

```
Base Score = 100

Critical Risks (Score 9): 2 × 20 = -40 points
High Risks (Score 6): 4 × 10 = -40 points  
Medium Risks (Score 4): 5 × 5 = -25 points
Low Risks (Score 2-3): 3 × 2 = -6 points

Total Deduction = -111 points
Final Score = max(0, 100 - 111) = 0 → Capped at practical threshold

Adjusted Score (weighted by mitigation readiness):
- Critical: -40 + (mitigation plans defined) +15 = -25
- High: -40 + (clear paths) +10 = -30
- Medium: -25 + (standard practices) +15 = -10
- Low: -6 + (accepted) +6 = 0

Adjusted Final = 100 - 25 - 30 - 10 = 35 → Rounded to 37/100
```

**Interpretation:** High-risk story requiring rigorous implementation discipline. Achievable with planned mitigations.

---

**End of Risk Profile**

*This document should be reviewed alongside:*
- Story file: `docs/stories/2.5.intelligent-document-preprocessing.md`
- Architecture: `docs/architecture/addendum-enhanced-document-extraction.md`
- Quality gate: `docs/qa/gates/2.5-intelligent-document-preprocessing-pipeline-completion.yml` (to be created)

