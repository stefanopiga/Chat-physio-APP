****# Story Validation – Story 2.8.1: Secret Governance e Resilienza Servizi Esterni

Data: 2025-10-14  
Revisore: Sarah (Product Owner)

## Summary

- Status: **Needs Updates**
- Blocking Issues: 3
- Observations: 3

## Template Compliance Issues

1. **Sezioni obbligatorie mancanti** – La story non contiene le sezioni `## Testing`, `## Change Log`, `## Dev Agent Record` e `## QA Results` previste dal template (`.bmad-core/templates/story-tmpl.yaml`).  
2. **Formato Tasks** – L’area “Tasks (Order)” non utilizza la struttura checklist con riferimenti AC come da template (`- [ ] Task (AC: #)`).

## Critical Issues (Must Fix)

### 1. Mancanza sezioni template per Dev/QA (Blocking)
- **Riferimento:** `docs/stories/2.8.1.secrets-resilience-and-p95-foundation.md`
- **Problema:** Assenza delle sezioni `Testing`, `Change Log`, `Dev Agent Record`, `QA Results` impedisce a dev e QA di tracciare progressi e risultanze secondo standard progetto.
- **Richiesta:** Ripristinare tutte le sezioni richieste dal template, mantenendo il contenuto attuale (“Validazione & Verifiche”) all’interno della sezione `Testing` o come sottosezione coerente.

### 2. Task non collegati agli Acceptance Criteria (Blocking)
- **Riferimento:** Story – sezione “Tasks (Order)”
- **Problema:** Le task non indicano esplicitamente quale AC soddisfano. Considerata la natura regolatoria (secrets, resilienza), serve tracciabilità AC→Task per evitare omissioni.
- **Richiesta:** Annotare ogni task con il riferimento AC (es. `- [ ] Configurare vault ... (AC1.1)`), includendo eventuali sottotask.

### 3. Test di resilienza e P95 citati ma file non specificati (Blocking)
- **Riferimento:** Sezione “Validazione & Verifiche” (pytest `test_openai_resilience.py`, script `--simulate-downtime`)
- **Problema:** Non è chiaro dove si trovano (o verranno creati) i file di test citati (`apps/api/tests/test_openai_resilience.py`, flag `--simulate-downtime` per connectivity script). Senza percorso/istruzioni, il dev rischia ambiguità.
- **Richiesta:** Aggiungere nel File List/Tasks le modifiche previste ai test (path, naming, eventuali nuovi script o parametri) e segnalarlo tra i deliverable.

## Should-Fix Issues

1. **Validazione & Verifiche** – Ribattezzare come sottosezione di `Testing`, chiarendo input/expected output per ogni comando (es. `detect-secrets scan` → file JSON).  
2. **Deliverables** – Includere il report JSON `detect-secrets-raw-YYYYMMDD.json` (già menzionato nelle verifiche) e indicare se i log del drill resilienza devono essere archiviati in `reports/`.  
3. **Source Tree Guidance** – In Dev Notes manca riferimento esplicito a dove collocare nuovi script/fixture (es. eventuali helper per simulare downtime). Aggiornare con percorso consigliato secondo struttura progetto.

## Nice-to-Have Improvements

- Aggiungere un elenco “Prerequisiti” all’inizio della sezione Validazione per ricordare di impostare variabili (`BASE_URL_TEST`, flag simulazione, accessi vault).  
- Valutare una tabella riepilogativa (AC ↔ Evidenza prevista) per facilitare QA/PO durante il gate finale.

## Anti-Hallucination Findings

- Tutti i riferimenti documentali puntano a file esistenti; tuttavia, i test citati (`test_openai_resilience.py`, flag CLI) non sono verificabili nel repository attuale → segnalato nel punto critico #3.

## Final Assessment

- **Esito:** NO-GO – adottare le correzioni sopra prima di passare a Ready for Dev.  
- **Implementation Readiness Score:** 6/10  
- **Confidence Level:** Medium – la direzione è corretta ma servono aggiustamenti strutturali per evitare fraintendimenti in fase di esecuzione.

---
Hook: `PO validation: docs/qa/assessments/2.8.1-po-validate-20251014.md`
