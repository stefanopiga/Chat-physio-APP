# NFR Assessment: Story 2.9 — Classification Performance Optimization

**Data:** 2025-10-14  
**Reviewer:** Quinn (Test Architect & Quality Advisor)  
**Story:** 2.9 — Classification Performance Optimization  
**Assessment Type:** Comprehensive NFRs (Performance, Reliability, Availability, Security, Scalability, Observability, Maintainability, Operability, Cost, Testability)

---

## Executive Summary

**Overall Status:** CONCERNS  
**Quality Score:** 78/100

La Story 2.9 introduce un caching Redis deterministico per i risultati della classificazione LLM con obiettivo di ridurre drasticamente la latenza (da ~11.4s a <100ms in caso di cache hit) e ripristinare la scalabilità della pipeline di ingestione. L’implementazione core è solida: chiavi con SHA-256 su testo+metadata, TTL configurabile, graceful fallback, metriche rolling e admin endpoints per invalidazione e stats. Tuttavia, il test di carico attuale mostra P95=59.98s perché lo scenario viene eseguito a cache fredda (nessun hit). Il rischio principale è operativo/di processo (mancato warmup), non tecnico.

**Status Breakdown:**
- ⚠️ Performance: CONCERNS (blocked by missing warmup in perf test)
- ✅ Reliability: PASS (con fallback e logging strutturato)
- ✅ Availability: PASS (degrada a classification diretta)
- ⚠️ Security: CONCERNS (endpoint admin sensibili; rate limit/authorization da verificare)
- ✅ Scalability: PASS (Redis DB isolato; overhead minimo per hit)
- ✅ Observability: PASS (eventi, stats, p50/p95 per hit/miss)
- ✅ Maintainability: PASS (modulo dedicato, tipizzato, doc)
- ⚠️ Operability: CONCERNS (procedura warmup non integrata nella pipeline di test)
- ✅ Cost: PASS (cache riduce chiamate LLM; richiede warmup)
- ✅ Testability: PASS (unit/integration presenti; perf script da adeguare)

---

## Scope & Evidence

- Implementazione cache: `apps/api/api/knowledge_base/classification_cache.py` (nuovo)
- Integrazione: `apps/api/api/knowledge_base/classifier.py` (lookup early, store post-invoke)
- Config: `CLASSIFICATION_CACHE_ENABLED`, `CLASSIFICATION_CACHE_TTL_SECONDS`, `classification_cache_redis_url`
- Admin endpoints: purge single, flush namespace, stats (router admin)
- Metriche P95 post-cache: `reports/metrics-p95-20251014-post-cache.md` (P95 59.98s con cache fredda)
- Story di riferimento: `docs/stories/2.9.classification-performance-optimization.md`

---

## Detailed Assessment

### 1) Performance — CONCERNS

Targets Story 2.9:
- Cache hit: <100ms; Miss: ~11.4s (invariato)
- Endpoint sync-jobs: P95 < 2s con 300 richieste

Evidenze:
- Nuovo cache layer con chiavi deterministiche su testo+metadata, TTL 7 giorni (default)
- Eventi `classification_cache_hit`/`_miss`/`_error` e rolling metrics p50/p95 per hit/miss
- Perf report 2025-10-14 mostra P95 59.98s con dataset unico (tutte miss)

Analisi:
- Il meccanismo funziona, ma lo scenario di carico non riflette l’uso reale atteso (alta ripetizione di contenuti → alta cache hit-rate).
- Warmup assente nello script `run_p95.ps1`; senza una prima passata di popolamento, non si osserva il beneficio.

Raccomandazioni (P0):
- Integrare warmup prima del test: ri-play del batch di documenti dallo stesso dataset per popolare Redis (DB1) e verificare hit-rate >90%.
- Rieseguire `run_p95.ps1` post-warmup; atteso P95 ~1s su sync-jobs.
- Aggiungere step “validate hit-rate” (via endpoint stats) all’interno dello script di perf.

### 2) Reliability — PASS

Evidenze:
- Fallback: se Redis non disponibile → classification diretta; eventi di errore strutturati
- `get_stats()` con conteggi hit/miss/error e percentili, utile a diagnosi regressioni
- Singleton cache con `get_classification_cache()` e ping di readiness

Rischi residui: bassi. Potenziale singolo punto di failure mitigato dal fallback.

Raccomandazioni (P1):
- Testare failure injection Redis (timeout/ping KO) nei test di integrazione per assicurare log di `classification_cache_error` ben formati.

### 3) Availability — PASS

Evidenze:
- Degrado controllato a classificazione diretta (no hard fail)
- TTL > 0 enforced; nessun lock-in di risorse Redis lato API

Raccomandazioni (P2):
- Aggiungere healthcheck dedicato a Redis DB1 (readiness probe opzionale).

### 4) Security — CONCERNS

Evidenze:
- Endpoints admin di purge/flush/stats sono sensibili; devono essere admin-only + rate-limited
- Nessun dato sensibile nei payload cache (risultato classificazione + metadata serializzati)

Rischi:
- Uso improprio di endpoint purge/flush può invalidare performance (cache thrash) o esporre info di attività (via stats) se non protetti correttamente.

Raccomandazioni (P0):
- Verificare/rafforzare protezione endpoint admin (authz admin, rate-limiting, audit log).
- Aggiungere test di autorizzazione e rate-limit sugli endpoint cache (integration).

### 5) Scalability — PASS

Evidenze:
- Namespace dedicato `classification:v1:*`, DB Redis isolato (DB1), chiavi O(1) su lookup
- Overhead minimo su hit; miss resta bound dal LLM (invariato)

Raccomandazioni (P2):
- Monitorare memoria Redis; configurare LRU + `maxmemory` se necessario per dataset grandi.

### 6) Observability — PASS

Evidenze:
- Eventi strutturati per hit/miss/error; metriche p50/p95 separate per hit/miss
- Endpoint stats “dashboard-ready” (hit_rate, latenze, size indicativa)

Raccomandazioni (P1):
- Esportare le metriche via endpoint dedicato JSON già previsto; integrare dashboard (Grafana/Loki/ELK) post-MVP.

### 7) Maintainability — PASS

Evidenze:
- Modulo isolato, tipizzato; funzioni di supporto per hashing/serializzazione metadata; docstring e struttura pulita
- Test unitari/integrazione per hit/miss/TTL/fallback indicati in Story

Raccomandazioni (P2):
- Coprire anche i code path di parsing error (difesa in profondità, low probability).

### 8) Operability — CONCERNS

Evidenze:
- Mancanza di warmup step automatizzato nella pipeline di performance testing

Raccomandazioni (P0):
- Aggiornare `scripts/perf/run_p95.ps1` o pipeline correlata per includere: (1) warmup ingestion con stesso batch, (2) verifica hit-rate >90%, (3) poi scenario di carico.

### 9) Cost — PASS

Evidenze:
- Con cache hit elevati, riduzione significativa chiamate LLM → cost saving

Raccomandazioni (P1):
- Aggiungere contatori costo per job ingestion (stimato/consuntivo) per validare il beneficio economico nel tempo.

### 10) Testability — PASS

Evidenze:
- Test unitari/integrazione definiti in Story; endpoint stats per assert quantitativi; facilità di esplorare hit-rate

Raccomandazioni (P1):
- Aggiungere test di sistema per la sequenza warmup→load test (black-box perf).

---

## Recommendations by Priority

### P0 (Pre-retest/perf gate)
1. Integrare warmup automatico prima di `run_p95.ps1` e validare hit-rate >90%.
2. Verificare/rinforzare protezioni sugli endpoint admin (authz + rate limit) con integration tests.

### P1 (Post-warmup, entro sprint)
3. Failure-injection Redis per validare fallback e logging errori; esportare stats su dashboard.
4. Tracciare costi LLM per job ingestion per osservare il beneficio economico del caching.

### P2 (Next sprint)
5. Healthcheck Redis DB1 e policy LRU/maxmemory; copertura test code path rari.

---

## Quality Score Calculation

```
Base: 100

Performance: Warmup mancante → -10
Security: Endpoint admin sensibili → -6
Reliability: Solido fallback/logging → 0
Availability: Degrado controllato → 0
Scalability: OK su Redis isolato → 0
Observability: Eventi+percentili → 0
Maintainability: Modulo isolato, tipizzato → 0
Operability: Warmup non in pipeline → -6
Cost: Beneficio chiaro (dipende da warmup) → 0
Testability: Buona (perf pipeline da adeguare) → 0

Finale: 100 - 10 - 6 - 6 = 78/100
```

**Gate Advisory:** CONCERNS fino a quando non si osserva P95 < 2s dopo warmup. Atteso PASS post-integrazione warmup.

---

## Appendix — Operational Notes

- Redis URL cache: se non impostato `classification_cache_redis_url`, deriva da `CELERY_BROKER_URL` spostando DB +1 (default `redis://localhost:6379/1`).
- Eventi chiave: `classification_cache_ready`, `classification_cache_hit|miss|error`, `classification_cache_flush`, `classification_cache_delete`.
- TTL: `CLASSIFICATION_CACHE_TTL_SECONDS` (default 604800 = 7 giorni). Flag: `CLASSIFICATION_CACHE_ENABLED`.
- Endpoint operativi (admin-only): purge by digest, flush namespace, stats JSON.

---

## Gate YAML (copy/paste)

```yaml
nfr_validation:
  _assessed: [performance, reliability, availability, security, scalability, observability, maintainability, operability, cost, testability]
  performance:
    status: CONCERNS
    notes: "P95 59.98s a cache fredda — integrare warmup e verificare hit-rate >90%"
    evidence:
      - path: reports/metrics-p95-20251014-post-cache.md:1
  reliability:
    status: PASS
    notes: "Fallback su miss/errore Redis con logging strutturato"
    evidence:
      - path: apps/api/api/knowledge_base/classification_cache.py:1
  availability:
    status: PASS
    notes: "Degrado controllato alla classificazione diretta"
  security:
    status: CONCERNS
    notes: "Endpoint admin (purge/flush/stats) da vincolare ad authz admin + rate limiting"
  scalability:
    status: PASS
    notes: "Redis DB isolato; chiavi O(1), overhead minimo su hit"
  observability:
    status: PASS
    notes: "Eventi hit/miss/error; metriche p50/p95 per hit/miss; endpoint stats"
  maintainability:
    status: PASS
    notes: "Modulo dedicato, tipizzato, testabile"
  operability:
    status: CONCERNS
    notes: "Warmup non integrato in pipeline di perf"
    remediation:
      - "Eseguire scripts/perf/warmup_classification_cache.py prima di run_p95.ps1"
  cost:
    status: PASS
    notes: "Cache riduce invocazioni LLM; beneficio dipende da hit-rate"
  testability:
    status: PASS
    notes: "Endpoint stats e test unit/integration definiti; aggiungere black-box perf warmup→load"
```

---

## Update 2025-10-14 (dettagliato)

- Rieseguita valutazione NFR sulla base degli ultimi file aperti e delle evidenze di performance. Confermati i seguenti punti:
  - Il fallimento del target P95 deriva dall’assenza di warmup e da dataset con payload unici; non da difetti del layer cache.
  - Lo script di warmup è presente ed utilizzabile: `scripts/perf/warmup_classification_cache.py:1`.
  - Il report di performance rilevante è `reports/metrics-p95-20251014-post-cache.md:1`.
- Azioni immediate raccomandate per sbloccare il gate NFR:
  1) Integrare warmup nel flusso di `scripts/perf/run_p95.ps1:1` con la stessa batch di documenti del test.
  2) Validare `CLASSIFICATION_CACHE_ENABLED=true` e readiness Redis (evento `classification_cache_ready`).
  3) Verificare hit-rate via endpoint stats (>90%) prima di avviare lo scenario k6.
  4) Rieseguire il test e aggiornare questo documento con i nuovi risultati.
