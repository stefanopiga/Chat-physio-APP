# Test Design: Story 4.2.3

Date: 2025-10-29
Designer: Quinn (Test Architect)

## Test Strategy Overview

- Total test scenarios: 12
- Unit tests: 5 (42%)
- Integration tests: 5 (42%)
- E2E tests: 2 (16%)
- Priority distribution: P0: 5, P1: 5, P2: 2

## Test Scenarios by Acceptance Criteria

### AC1: Feedback Dashboard Counts Corretti

#### Scenarios

| ID             | Level       | Priority | Test                                                                               | Justification |
| 4.2.3-UNIT-001 | Unit        | P1       | Compute positive/negative percentages from votes array (2 up,1 down → 66.7/33.3)   | Pure calculation |
| 4.2.3-INT-001  | Integration | P0       | aggregate_analytics summary reflects votes present in feedback_store                | Store→function integration |
| 4.2.3-E2E-001  | E2E         | P1       | UI shows non-zero thumbs_up/thumbs_down when feedback exists                        | Critical dashboard visibility |

### AC2: Query Problematiche Non Vuota

#### Scenarios

| ID             | Level       | Priority | Test                                                                                     | Justification |
| 4.2.3-UNIT-002 | Unit        | P0       | Map assistant message id → preceding user query text via helper                          | Core pairing logic |
| 4.2.3-INT-002  | Integration | P0       | aggregate_problematic_queries returns total_count > 0 when negative feedback exists      | End-to-end function path |
| 4.2.3-INT-003  | Integration | P1       | Top-5 list includes exact user query with one downvote                                   | Correct mapping and counting |

### AC3: Engagement Tasso Conversione Feedback Corretto

#### Scenarios

| ID             | Level       | Priority | Test                                                                                  | Justification |
| 4.2.3-UNIT-003 | Unit        | P1       | Compute feedback_conversion_rate: 2/3 → 0.667                                          | Pure calculation |
| 4.2.3-INT-004  | Integration | P0       | aggregate_engagement_stats counts assistant ids with feedback keys exactly              | Store key lookup correctness |

### AC4: Unit Tests Fix Validation

#### Scenarios

| ID             | Level       | Priority | Test                                                                               | Justification |
| 4.2.3-UNIT-004 | Unit        | P0       | Helper handles sequences: user→assistant, system in-between, missing assistant         | Edge-case pairing risks |
| 4.2.3-UNIT-005 | Unit        | P2       | Helper stable under multiple assistants per user (uses first proper assistant only)    | Defensive behavior |

### AC5: Manual Testing Verification

#### Scenarios

| ID             | Level       | Priority | Test                                                                 | Justification |
| 4.2.3-E2E-002  | E2E         | P1       | Full flow: 3 questions, 2 up, 1 down → dashboard matches expected    | End-to-end validation |

### AC6: No Regression - Existing Functionality Intact

#### Scenarios

| ID             | Level       | Priority | Test                                                                                 | Justification |
| 4.2.3-INT-005  | Integration | P1       | Run existing analytics tests (Story 4.2.2) and ensure they pass                      | Regression safety |

## Detailed Scenario Specs

- 4.2.3-UNIT-002 (Pairing helper):
  - Given messages: [user(id=local1,"Q1"), system("…"), assistant(id=A1,"R1")]
  - When pairing
  - Then returns mapping {A1:"Q1"}
  - And missing assistant yields no mapping

- 4.2.3-INT-004 (Engagement exact key):
  - Given session=S, assistant ids A1,A2,A3; feedback keys {S:A1, S:A2}
  - When aggregating engagement
  - Then queries_with_feedback=2, rate≈0.667

- 4.2.3-INT-002/003 (Problematic queries):
  - Given one downvote on A1 for query "Q bad"
  - Then total_count=1 and top list contains "Q bad" with negative_feedback_count=1

## Risk Coverage

- Covers TECH-002 (pairing edge cases): 4.2.3-UNIT-002, 4.2.3-UNIT-004, 4.2.3-INT-002/003
- Covers TECH-003 (test gaps): AC4 scenarios increase coverage on modified functions
- Covers PERF-001 (lookup): 4.2.3-INT-004 validates exact-key path
- Covers BUS-001 (trust): E2E checks confirm visible metrics

## Recommended Execution Order

1. P0 Unit: 4.2.3-UNIT-002, 4.2.3-UNIT-004
2. P0 Integration: 4.2.3-INT-002, 4.2.3-INT-004
3. P1 Integration: 4.2.3-INT-001, 4.2.3-INT-003, 4.2.3-INT-005
4. P1 E2E: 4.2.3-E2E-001, 4.2.3-E2E-002
5. Remaining Unit: 4.2.3-UNIT-001, 4.2.3-UNIT-003, 4.2.3-UNIT-005

## Notes for Implementation

- Prefer building a small utility for assistant-id lookup and unit test it thoroughly.
- For integration tests, build minimal fixtures: in-memory `chat_messages_store` and `feedback_store`.
- Use exact feedback key membership `{session}:{assistant_id}` to avoid substring false positives.
